# 第八章。编写渲染引擎

在前面的一章中，我们学习了如何在移动和桌面 OpenGL 之上组织一个薄抽象层。现在，我们可以进入实际的渲染领域，并使用这个层来实现一个三维渲染框架，该框架能够使用材质、灯光和阴影渲染从文件加载的几何图形。

# 场景图

场景图是一种数据结构，通常用于构建空间图形场景的分层表示。[第 6 章](06.html#aid-1MBG21 "Chapter 6. OpenGL ES 3.1 and Cross-platform Rendering")、 *OpenGL ES 3.1、跨平台渲染*引入的类的主要局限性是缺乏整体场景的信息。这些类的用户必须对转换、状态变化和依赖关系进行临时记账，这使得实现和支持任何稍微复杂的场景成为一项非常具有挑战性的任务。此外，除非可以访问当前帧的整个场景信息，否则无法进行大量渲染优化。

在我们当前的低级实现中，我们使用`clVertexArray`类描述所有可见的实体，并使用可通过`clGLSLShaderProgram`类访问的着色器程序渲染它们，矩阵和着色器参数的手动绑定很难看。让我们学习如何将所有这些属性组合到一个更高级别的数据结构中。首先，我们将从场景图节点开始。

`clSceneNode`类包含局部和全局变换以及一个子节点向量。这些字段受到保护，我们使用 setters 和 getters 来访问它们:

```
class clSceneNode: public iIntrusiveCounter
{
protected:
  mat4 m_LocalTransform;
  mat4 m_GlobalTransform;
  std::vector< clPtr<clSceneNode> > m_ChildNodes;
```

当我们需要层次结构时，我们必须区分节点的全局和局部转换。从用户的角度来看，本地转换很容易理解。这定义了层次空间结构中节点相对于其父节点的位置和方向。全局变换用于渲染几何图形。*本身*，它将几何从模型坐标系转换为世界坐标系。局部转换可以通过手工直观地修改，全局转换应该随后重新评估。`clSceneNode`的构造函数设置默认的变换值:

```
public:
  clSceneNode():
  m_LocalTransform( mat4::Identity() ),
  m_GlobalTransform( mat4::Identity() ) {}
```

`clSceneNode`类包含访问和修改转换矩阵的设置器和获取器。实现简单。然而，它相当麻烦，所以这里只引用局部变换矩阵的方法。完整图片请查看源代码`1_SceneGraphRenderer`:

```
  void SetLocalTransform( const mat4& Mtx )
  { m_LocalTransform = Mtx; }
  const mat4& GetLocalTransformConst() const
  { return m_LocalTransform; }
  mat4& GetLocalTransform()
  { return m_LocalTransform; };
```

除此之外，我们还需要一个方法来给这个场景节点添加一个子节点。我们当前的实现非常简单:

```
  virtual void Add( const clPtr<clSceneNode>& Node )
  {
    m_ChildNodes.push_back( Node );
  }
```

但是，这种方法可以在将来扩展，以允许某些优化。例如，一旦我们添加了新节点，我们就可以将场景图的某些部分标记为脏。这将允许我们保留从场景图构建的帧间渲染队列。

有时需要直接设置全局变换矩阵。例如，如果您想在 3D 应用程序中使用物理模拟库。一旦完成，就应该重新计算本地转换。`RecalculateLocalFromGlobal()`方法计算层次结构中每个节点的相对局部变换。对于根节点，本地和全局转换是一致的。对于子代，每个全局变换矩阵必须乘以其父代的逆全局变换:

```
  void RecalculateLocalFromGlobal()
  {
    mat4 ParentInv = m_GlobalTransform.GetInversed();
    for ( auto& i : m_ChildNodes )
    {
```

我们将父节点的全局逆变换乘以当前节点的全局变换:

```
    i->SetLocalTransform( ParentInv * i->GetGlobalTransform() );
```

该过程沿层级向下重复:

```
    i->RecalculateLocalFromGlobal();
  }
}
```

`clSceneNode`的宣言中还剩下一件有趣的事情。这就是纯虚法`AcceptTraverser()`。为了渲染场景图，使用了一种称为 *访客设计模式*的技术([https://en.wikipedia.org/?title=Visitor_pattern](https://en.wikipedia.org/?title=Visitor_pattern)):

```
virtual void AcceptTraverser(iSceneTraverser* Traverser) = 0;
```

`iSceneTraverser`界面用于定义场景图上的不同操作。由于不同类型的场景图节点数量有限且不变，我们只需实现`iSceneTraverser`界面就可以添加新的操作:

```
class iSceneTraverser: public iIntrusiveCounter
{
public:
  virtual void Traverse( clPtr<clSceneNode> Node );
  virtual void Reset() = 0;
```

该接口被声明为`clSceneNode`的所有后代的朋友，以允许直接访问这些类的字段:

```
  friend class clSceneNode;
  friend class clMaterialNode;
  friend class clGeometryNode;
protected:
  virtual void PreAcceptSceneNode( clSceneNode* Node ) {};
  virtual void PostAcceptSceneNode( clSceneNode* Node ) {};
  virtual void PreAcceptMaterialNode( clMaterialNode* Node ) {};
  virtual void PostAcceptMaterialNode( clMaterialNode* Node ){};
  virtual void PreAcceptGeometryNode( clGeometryNode* Node ) {};
  virtual void PostAcceptGeometryNode( clGeometryNode* Node ){};
};
```

`Traverse()`的实现由所有遍历器共享。它重置遍历器并调用虚拟方法`clSceneNode::AcceptTraverser()`:

```
void iSceneTraverser::Traverse( clPtr<clSceneNode> Node )
{
  if ( !Node ) return;
  Reset();
  Node->AcceptTraverser( this );
}
```

在`iSceneTraverser`的声明中，可以看到另外两种类型的场景节点。`clSceneNode`对象的树可以保存空间变换的层次结构。显然，这还不足以渲染任何东西。为此，我们至少需要几何数据和一种材料。

为此我们再声明两个类:`clMaterialNode`和`clGeometryNode`。

对于本章的第一个示例，材质将只包含环境色和漫射色([https://en.wikipedia.org/wiki/Phong_shading](https://en.wikipedia.org/wiki/Phong_shading)):

```
struct sMaterial
{
public:
  sMaterial()
  : m_Ambient( 0.2f )
  , m_Diffuse( 0.8f )
  , m_MaterialClass()
  {}
  vec4 m_Ambient;
  vec4 m_Diffuse;
```

字段`m_MaterialClass`包含一个材质标识符，可用于区分特殊材质，例如，为粒子渲染启用 alpha 透明度:

```
  std::string m_MaterialClass;
};
```

现在，可以声明一个材质场景节点。这是一个简单的数据容器:

```
class clMaterialNode: public clSceneNode
{
public:
  clMaterialNode() {};
  sMaterial& GetMaterial() { return m_Material; }
  const sMaterial& GetMaterial() const { return m_Material; }
  void SetMaterial( const sMaterial& Mtl ) { m_Material = Mtl; }
  virtual void AcceptTraverser(iSceneTraverser* Traverser) override;
private:
  sMaterial m_Material;
};
```

我们来看一下的`AcceptTraverser()`方法实现。它非常简单而且非常有效:

```
void clMaterialNode::AcceptTraverser( iSceneTraverser* Traverser )
{
  Traverser->PreAcceptSceneNode( this );
  Traverser->PreAcceptMaterialNode( this );
  AcceptChildren( Traverser );
  Traverser->PostAcceptMaterialNode( this );
  Traverser->PostAcceptSceneNode( this );
}
```

几何节点稍微复杂一点。这是因为`clVertexAttribs`中与 API 无关的几何数据表示应该被馈送到`clGLVertexArray`的实例中:

```
class clGeometryNode: public clSceneNode
{
public:
  clGeometryNode() {};
  clPtr<clVertexAttribs> GetVertexAttribs() const
  { return m_VertexAttribs; }
  void SetVertexAttribs( const clPtr<clVertexAttribs>& VA )
  { m_VertexAttribs = VA; }
```

在这里，我们以一种懒惰的方式将几何数据输入到 OpenGL 中:

```
  clPtr<clGLVertexArray> GetVA() const
  {
    if ( !m_VA )
    {
      m_VA = make_intrusive<clGLVertexArray>();
      m_VA->SetVertexAttribs( m_VertexAttribs );
    }
    return m_VA;
  }
  virtual void AcceptTraverser(iSceneTraverser* Traverser) override;
private:
  clPtr<clVertexAttribs> m_VertexAttribs;
  mutable clPtr<clGLVertexArray> m_VA;
};
```

`AcceptTraverser()`的实现和`clMaterialNode`里面的非常相似。只要看看捆绑的源代码。

正如你所看到的，整个场景节点类只不过是一个简单的数据容器。实际操作发生在 traverser 类中。`iSceneTraverser`的第一个实现是`clTransformUpdateTraverser`类，它更新了每个场景节点的全局——这意味着相对于图的根——变换:

```
class clTransformUpdateTraverser: public iSceneTraverser
{
private:
  std::vector<mat4> m_ModelView;
```

私有字段`m_ModelView`包含一堆实现为`std::vector`的矩阵。这个堆栈的顶部元素是节点的当前全局转换。`Reset()`方法清除堆栈，并将身份矩阵推送到堆栈上，稍后用作根场景节点的全局变换:

```
public:
  clTransformUpdateTraverser(): m_ModelView() {}
  virtual void Reset() override
  {
    m_ModelView.clear();
    m_ModelView.push_back( mat4::Identity() );
  }
```

`PreAcceptSceneNode()`方法将当前全局变换的一个新值推送到`m_ModelView`栈上，然后将其用作传入节点的全局变换:

```
protected:
  virtual void PreAcceptSceneNode( clSceneNode* Node ) override
  {
    m_ModelView.push_back( Node->GetLocalTransform() * m_ModelView.back() );
    Node->SetGlobalTransform( m_ModelView.back() );
  }
```

`PostAcceptSceneNode()`方法从堆栈中弹出最上面的、现在未使用的矩阵:

```
  virtual void PostAcceptSceneNode( clSceneNode* Node ) override
  {
    m_ModelView.pop_back();
  }
};
```

在渲染任何几何图形之前，此遍历器用于每个帧的开头:

```
clTransformUpdateTraverser g_TransformUpdateTraverser;
clPtr<clSceneNode> g_Scene;
g_TransformUpdateTraverser.Traverse( g_Scene );
```

我们现在几乎已经准备好进行实际渲染了。为此，我们需要将场景图线性化为渲染操作向量。让我们来看看`ROP.h`文件。每个渲染操作都是一个独立的几何体、一个材质和一堆变换矩阵。所需的矩阵存储在`sMatrices`结构中:

```
struct sMatrices
{
```

投影、视图和模型矩阵是从外部状态显式设置的:

```
  mat4 m_ProjectionMatrix;
  mat4 m_ViewMatrix;
  mat4 m_ModelMatrix;
```

使用`UpdateMatrices()`方法更新照明和阴影所需的其他矩阵:

```
  mat4 m_ModelViewMatrix;
  mat4 m_ModelViewMatrixInverse;
  mat4 m_ModelViewProjectionMatrix;
  mat4 m_NormalMatrix;
  void UpdateMatrices()
  {
    m_ModelViewMatrix = m_ModelMatrix * m_ViewMatrix;
    m_ModelViewMatrixInverse = m_ModelViewMatrix.GetInversed();
    m_ModelViewProjectionMatrix = m_ModelViewMatrix * m_ProjectionMatrix;
    m_NormalMatrix = mat4( m_ModelViewMatrixInverse.ToMatrix3().GetTransposed() );
  }
};
```

这种结构可以很容易地根据需要用额外的矩阵来扩展。此外，将此结构的值打包到统一缓冲区对象中非常方便。

现在，我们的渲染操作可以如下所示:

```
class clRenderOp
{
public:
  clRenderOp( const clPtr<clGeometryNode>& G, const clPtr<clMaterialNode>& M):
    m_Geometry(G), m_Material(M) {}
  void Render( sMatrices& Matrices ) const;
  clPtr<clGeometryNode> m_Geometry;
  clPtr<clMaterialNode> m_Material;
};
```

在`ROP.cpp`中可以找到`clRenderOp::Render()`的极简实现。这里定义了两个着色器。首先，一个普通的顶点着色器将法线转换到世界空间:

```
static const char g_vShaderStr[] = R"(
  uniform mat4 in_ModelViewProjectionMatrix;
  uniform mat4 in_NormalMatrix;
  uniform mat4 in_ModelMatrix;
  in vec4 in_Vertex;
  in vec2 in_TexCoord;
  in vec3 in_Normal;
  out vec2 v_Coords;
  out vec3 v_Normal;
  out vec3 v_WorldNormal;
  void main()
  {
    v_Coords = in_TexCoord.xy;
    v_Normal = mat3(in_NormalMatrix) * in_Normal;
    v_WorldNormal = ( in_ModelMatrix * vec4( in_Normal, 0.0 ) ).xyz;
    gl_Position = in_ModelViewProjectionMatrix * in_Vertex;
  }
)";
```

然后，片段着色器使用指向与相机相同方向的单向光源进行简单的每像素照明:

```
static const char g_fShaderStr[] = R"(
  in vec2 v_Coords;
  in vec3 v_Normal;
  in vec3 v_WorldNormal;
  out vec4 out_FragColor;
  uniform vec4 u_AmbientColor;
  uniform vec4 u_DiffuseColor;
  void main()
  {
    vec4 Ka = u_AmbientColor;
    vec4 Kd = u_DiffuseColor;
```

摄像机是静态定位的，照明是在世界空间中完成的:

```
    vec3 L = normalize( vec3( 0.0, 0.0, 1.0 ) );
    float d = clamp( dot( L, normalize(v_WorldNormal) ), 0.0, 1.0 );
    vec4 Color = Ka + Kd * d;
    out_FragColor = Color;
  }
)";
```

静态全局变量保存使用前面代码中提到的着色器链接的着色器程序:

```
clPtr<clGLSLShaderProgram> g_ShaderProgram;
```

实际渲染代码更新所有矩阵，设置着色器程序的参数，并渲染几何图形:

```
void clRenderOp::Render( sMatrices& Matrices ) const
{
  if ( !g_ShaderProgram )
  {
    g_ShaderProgram = make_intrusive<clGLSLShaderProgram>( g_vShaderStr, g_fShaderStr );
  }
  Matrices.m_ModelMatrix = this->m_Geometry->GetGlobalTransformConst();
  Matrices.UpdateMatrices();
```

一旦渲染操作和制服的数量增加，下面这段代码将成为瓶颈。它可以通过使用预制的统一位置来改进:

```
  g_ShaderProgram->Bind();
  g_ShaderProgram->SetUniformNameVec4Array( "u_AmbientColor", 1, this->m_Material->GetMaterial().m_Ambient );
  g_ShaderProgram->SetUniformNameVec4Array( "u_DiffuseColor", 1, this->m_Material->GetMaterial().m_Diffuse );
  g_ShaderProgram->SetUniformNameMat4Array( in_ProjectionMatrix", 1, Matrices.m_ProjectionMatrix );
  g_ShaderProgram->SetUniformNameMat4Array( "in_ViewMatrix", 1, Matrices.m_ViewMatrix );
  g_ShaderProgram->SetUniformNameMat4Array( "in_ModelMatrix", 1, Matrices.m_ModelMatrix );
  g_ShaderProgram->SetUniformNameMat4Array( "in_NormalMatrix", 1, Matrices.m_NormalMatrix );
  g_ShaderProgram->SetUniformNameMat4Array( "in_ModelViewMatrix", 1, Matrices.m_ModelViewMatrix );
  g_ShaderProgram->SetUniformNameMat4Array( "in_ModelViewProjectionMatrix", 1, Matrices.m_ModelViewProjectionMatrix );
  this->m_Geometry->GetVA()->Draw( false );
}
```

让我们将场景图转换成渲染操作的向量，这样我们就可以看到实际渲染的图像。这是由`clROPsTraverser`类完成的:

```
class clROPsTraverser: public iSceneTraverser
{
private:
  std::vector<clRenderOp> m_RenderQueue;
  std::vector<clMaterialNode*> m_Materials;
public:
  clROPsTraverser()
  : m_RenderQueue()
  , m_Materials() {}
```

在构建渲染操作的新队列之前，清除一切:

```
  virtual void Reset() override
  {
    m_RenderQueue.clear();
    m_Materials.clear();
  }
```

返回对最近构造的队列的引用:

```
  virtual const std::vector<clRenderOp>& GetRenderQueue() const
  {
    return m_RenderQueue;
  }
```

现在，我们实现`iSceneTraverser`接口。这里的大多数方法都是空的:

```
protected:
  virtual void PreAcceptSceneNode( clSceneNode* Node ) override
  {
  }
  virtual void PostAcceptSceneNode( clSceneNode* Node ) override
  {
  }
```

当下一个几何节点进入时，使用材质堆栈中最上面的材质，并创建一个新的渲染操作:

```
  virtual void PreAcceptGeometryNode( clGeometryNode* Node ) override
  {
    if ( !m_Materials.size() ) return;
    m_RenderQueue.emplace_back( Node, m_Materials.front() );
  }
  virtual void PostAcceptGeometryNode( clGeometryNode* Node ) override
  {
  }
```

每次入库`clMaterialNode`都会更新材料栈:

```
  virtual void PreAcceptMaterialNode( clMaterialNode* Node ) override
  {
    m_Materials.push_back( Node );
  }
  virtual void PostAcceptMaterialNode( clMaterialNode* Node ) override
  {
    m_Materials.pop_back();
  }
};
```

最后，这个框架现在可以用来渲染实际的 3D 图形。示例场景在`1_SceneGraphRenderer/main.cpp`中创建。首先，我们场景的根被创建:

```
g_Scene = make_intrusive<clSceneNode>();
```

创建红色材质并将其绑定到材质场景节点:

```
auto MaterialNode = make_intrusive<clMaterialNode>();
sMaterial Material;
Material.m_Ambient = vec4( 0.1f, 0.0f, 0.0f, 1.0f );
Material.m_Diffuse = vec4( 0.9f, 0.0f, 0.0f, 1.0f );
MaterialNode->SetMaterial( Material );
```

让我们创建一个以原点为中心的立方体:

```
auto VA = clGeomServ::CreateAxisAlignedBox( vec3(-1), vec3(+1) );
g_Box= make_intrusive<clGeometryNode>();
g_Box->SetVertexAttribs( VA );
MaterialNode->Add( g_Box );
```

把它加入场景:

```
g_Scene->Add( MaterialNode );
```

渲染简单明了，非常通用:

```
void OnDrawFrame()
{
  static float Angle = 0.0f;
```

围绕对角线旋转立方体:

```
  g_Box->SetLocalTransform( mat4::GetRotateMatrixAxis( Angle, vec3( 1, 1, 1 ) ) );
  Angle += 0.01f;
```

更新节点的全局变换并构建渲染队列:

```
  g_TransformUpdateTraverser.Traverse( g_Scene );
  g_ROPsTraverser.Traverse( g_Scene );
  const auto& RenderQueue = g_ROPsTraverser.GetRenderQueue();
```

设置矩阵。摄像机只有一个虚拟实现，它当前返回一个身份视图矩阵:

```
  sMatrices Matrices;
  Matrices.m_ProjectionMatrix = Math::Perspective( 45.0f, g_Window->GetAspect(), 0.4f, 2000.0f );
  Matrices.m_ViewMatrix = g_Camera.GetViewMatrix();
```

在渲染帧之前清除屏幕:

```
  LGL3->glClear( GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT );
  LGL3->glEnable( GL_DEPTH_TEST );
```

迭代渲染队列并渲染所有内容:

```
  for ( const auto& ROP : RenderQueue )
  {
    ROP.Render( Matrices );
  }
}
```

生成的图像如下图所示:

![The scene graph](../Images/image00225.jpeg)

现在让我们用灯光和阴影扩展我们的场景图渲染示例，并确保在安卓上一切正常。

# 照明和遮阳

为了渲染灯光和阴影，我们需要扩展前面段落中显示的方法。我们将讨论的下一个代码示例是`2_ShadowMaps`。阴影贴图将使用投影阴影贴图([https://en.wikipedia.org/wiki/Shadow_mapping](https://en.wikipedia.org/wiki/Shadow_mapping))完成。这样，从灯光的角度来看，场景被渲染到屏幕外的深度缓冲区中。接下来，场景照常渲染，每个片段都被投影到灯光阴影贴图上，相对于灯光的深度值与构建的阴影贴图中的值进行比较。如果深度值大于阴影贴图中相应的深度值，则片段处于阴影中。要进行屏下渲染，我们需要重温[第 6 章](06.html#aid-1MBG21 "Chapter 6. OpenGL ES 3.1 and Cross-platform Rendering")、 *OpenGL ES 3.1 和跨平台渲染*中介绍的 OpenGL 包装器，并为其添加一个 framebuffer 抽象。

`clGLFrameBuffer`类在`GLFrameBuffer.h`中声明:

```
class clGLFrameBuffer: public iIntrusiveCounter
{
public:
  clGLFrameBuffer():
  FFrameBuffer(0),
  FColorBuffer(),
  FDepthBuffer(),
  FColorBuffersParams(),
  FHasDepthBuffer( false )
  {}
  virtual ~clGLFrameBuffer();
```

方法`InitRenderTargetV()`接受包含每个通道的宽度、高度和位数的整数值的向量:

```
  virtual void InitRenderTargetV( const ivec4& WidthHeightBitsPerChannel, const bool HasDepthBuffer );
```

此方法提供对私有数据成员的访问，这些成员是宽度、高度和每个通道的位数，它们被传递到`InitRenderTargetV()`:

```
  virtual ivec4 GetParameters() const
  {
    return FColorBuffersParams;
  }
```

framebuffer 最重要的功能是能够以纹理形式提供其内容，即颜色纹理和深度纹理:

```
  virtual clPtr<clGLTexture> GetColorTexture() const
  {
    return FColorBuffer;
  }
  virtual clPtr<clGLTexture> GetDepthTexture() const
  {
    return FDepthBuffer;
  }
```

`Bind()`方法将该帧缓冲区设置为当前 OpenGL 帧缓冲区:

```
  virtual void Bind( int TargetIndex ) const;
  virtual void UnBind() const;
```

保护方法`CheckFrameBuffer()`用于根据 OpenGL 规范检查帧缓冲区的完整性:

```
protected:
  void CheckFrameBuffer() const;
```

该类的私有部分包含一个 OpenGL 缓冲区标识符，两个分别用于颜色和深度纹理的`clGLTexture`对象，以及两个包含帧缓冲区参数的字段:

```
private:
  GLuint FFrameBuffer;
  clPtr<clGLTexture> FColorBuffer;
  clPtr<clGLTexture> FDepthBuffer;
  ivec4 FColorBuffersParams;
  bool FHasDepthBuffer;
};
```

正确的为安卓和其他平台构建帧缓冲区需要一些工作和仔细选择参数。我们来看看`InitRenderTargetV()`成员函数的实现:

```
void clGLFrameBuffer::InitRenderTargetV( const ivec4& WidthHeightBitsPerChannel, const bool HasDepthBuffer )
{
```

首先，我们将 framebuffer 的参数存储在私有数据成员中。这些值稍后将用于视口外观计算:

```
  FColorBuffersParams = WidthHeightBitsPerChannel;
  FHasDepthBuffer = HasDepthBuffer;
```

接下来，我们将调用 OpenGL 函数来创建一个 framebuffer 对象:

```
  LGL3->glGenFramebuffers( 1, &FFrameBuffer );
```

一旦创建了 framebuffer 对象，我们就可以将其绑定为当前 framebuffer 来设置其属性:

```
  Bind( 0 );
```

创建颜色纹理并将其附加到帧缓冲区:

```
  FColorBuffer = make_intrusive<clGLTexture>();
  int Width = FColorBuffersParams[0];
  int Height = FColorBuffersParams[1];
```

安卓和桌面实现的唯一区别是缓冲数据格式的选择。OpenGL 4 Core Profile 要求明确指定内部格式和深度格式的位数，而 OpenGL ES 3 则希望分别通用`GL_RGBA`和`GL_DEPTH_COMPONENT`。我们以特定于平台的方式声明了两个常数:

```
  #if defined( OS_ANDROID )
    const Lenum InternalFormat = GL_RGBA;
    auto DepthFormat = GL_DEPTH_COMPONENT;
  #else
    const Lenum InternalFormat = GL_RGBA8;
    auto DepthFormat = GL_DEPTH_COMPONENT24;
  #endif
```

我们将调用`clGLTexture`的`SetFormat()`方法来设置颜色纹理的格式:

```
  FColorBuffer->SetFormat( GL_TEXTURE_2D, InternalFormat, GL_RGBA, Width, Height );
```

`AttachToCurrentFB()`方法将创建的颜色纹理附加到当前绑定的帧缓冲区。`GL_COLOR_ATTACHMENT0`的值指定了一个 OpenGL 附着点:

```
  FColorBuffer->AttachToCurrentFB( GL_COLOR_ATTACHMENT0 );
```

阴影贴图包含深度缓冲值，因此我们根据需要按照以下方式创建深度纹理:

```
  if ( HasDepthBuffer )
  {
    FDepthBuffer = make_intrusive<clGLTexture>();
```

深度缓冲区应与颜色缓冲区具有相同的尺寸:

```
    int Width = FColorBuffersParams[0];
    int Height = FColorBuffersParams[1];
```

深度缓冲区的设置类似于颜色缓冲区的设置:

```
    FDepthBuffer->SetFormat( GL_TEXTURE_2D, DepthFormat, GL_DEPTH_COMPONENT, Width, Height );
    FDepthBuffer->AttachToCurrentFB( GL_DEPTH_ATTACHMENT );
  }
```

为了确保正确操作，我们将检查错误代码并解除缓冲区绑定:

```
  CheckFrameBuffer();
  UnBind();
}
```

`CheckFrameBuffer()`成员函数使用 OpenGL 调用来检查帧缓冲区的当前状态:

```
void clGLFrameBuffer::CheckFrameBuffer() const
{
  Bind( 0 );
  GLenum FBStatus = LGL3->glCheckFramebufferStatus( GL_FRAMEBUFFER );
```

将错误代码转换为字符串并打印到系统日志中:

```
  switch ( FBStatus )
  {
    case GL_FRAMEBUFFER_COMPLETE: // Everything's OK
      break;
    case GL_FRAMEBUFFER_INCOMPLETE_ATTACHMENT:
      LOGI( "GL_FRAMEBUFFER_INCOMPLETE_ATTACHMENT" );
      break;
    case GL_FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT:
      LOGI("GL_FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT" );
      break;
```

OpenGL ES 是缺少了 OpenGL 的一些功能。这里，我们省略它们以使代码可移植:

```
    #if !defined(OS_ANDROID)
      case GL_FRAMEBUFFER_INCOMPLETE_DRAW_BUFFER:
        LOGI( "GL_FRAMEBUFFER_INCOMPLETE_DRAW_BUFFER" );
        break;
      case GL_FRAMEBUFFER_INCOMPLETE_READ_BUFFER:
        LOGI( "GL_FRAMEBUFFER_INCOMPLETE_READ_BUFFER" );
        break;
    #endif
      case GL_FRAMEBUFFER_UNSUPPORTED:
        LOGI( "GL_FRAMEBUFFER_UNSUPPORTED" );
        break;
      default:
        LOGI( "Unknown framebuffer error: %x", FBStatus );
  }
```

默认情况下，不打印任何内容:

```
  UnBind();
}
```

让我们继续前进，这样我们就可以利用这门课。

# 灯光和灯光节点

将光源表示为三维场景的一部分非常方便。当我们写“3D 场景”时，我们指的是场景图。为了将光源附加到场景图，我们需要一个特殊的节点。这里是`clLightNode`类，它持有一个指向`iLight`的指针，包含所有的光线属性:

```
class clLightNode: public clSceneNode
{
public:
  clLightNode() {}
  clPtr<iLight> GetLight() const
  {
    return m_Light;
  }
  void SetLight( const clPtr<iLight>& L )
  {
    m_Light = L;
  }
  virtual void AcceptTraverser( iSceneTraverser* Traverser )
    override;
  clPtr<iLight> m_Light;
};
```

`AcceptTraverser()`方法类似于`clGeometryNode`和`clMaterialNode`中的方法。但是这一次，我们将`iSceneTraverser`的`PreAcceptLightNode()`和`PostAcceptLightNode()`方法称为:

```
void clLightNode::AcceptTraverser( iSceneTraverser* Traverser )
{
  Traverser->PreAcceptSceneNode( this );
  Traverser->PreAcceptLightNode( this );
  AcceptChildren( Traverser );
  Traverser->PostAcceptLightNode( this );
  Traverser->PostAcceptSceneNode( this );
}
```

这个新的场景节点类型强制我们扩展`iSceneTraverser`的界面:

```
protected:
friend class clLightNode;
virtual void PreAcceptLightNode( clLightNode* Node ) {}
virtual void PostAcceptLightNode( clLightNode* Node ) {}
```

Traversers 现在可以用一种特殊的方式处理光节点。我们将使用这种能力来维护场景中每帧的活动灯光列表。

`iLight`类封装了灯光参数。它计算光源所需的投影矩阵和视图矩阵，将它们传递给着色器程序并保存阴影贴图。我们应该注意到，为可能未使用的光源保存一个初始化的阴影贴图肯定不是最佳的。在我们的极简示例中，我们至少可以将阴影贴图的创建推迟到真正需要的时候。在我们的例子中，我们将只处理聚光灯。但是，这种方法可以通过方向灯和点灯轻松扩展:

```
class iLight: public iIntrusiveCounter
{
public:
  iLight():
  m_Ambient(0.2f),
  m_Diffuse(0.8f),
  m_Position(0),
  m_Direction(0.0f, 0.0f, 1.0f),
```

如果您想要实现多种类型的灯光，建议将该字段下推到代表聚光灯的类别。由于我们的示例只有单一类型的灯光，因此将此值放在这里是一个合理的折衷方案:

```
  m_SpotOuterAngle(45.0f)
  {}
```

`UpdateROPUniforms()`方法更新阴影贴图渲染所需的着色器程序中的所有制服。`iLight`结束后，详细描述`clMaterialSystem`课程:

```
  void UpdateROPUniforms( const std::vector<clRenderOp>& ROPs, const clPtr<clMaterialSystem>& MatSys, const clPtr<clLightNode>& LightNode ) const;
```

为了从光线的角度渲染场景，我们需要计算两个矩阵。第一个是定义光的视图矩阵的标准*观察*矩阵，第二个是定义光的平截头体的透视投影矩阵:

```
  mat4 GetViewForShadowMap() const
  {
    return Math::LookAt( m_Position, m_Position + m_Direction, vec3( 0, 0, 1 ) );
  }
  mat4 GetProjectionForShadowMap() const
  {
    float NearCP = 0.1f;
    float FarCP = 1000.0f;
    return Math::Perspective( 2.0f * this->m_SpotOuterAngle, 1.0f, NearCP, FarCP );
  }
```

`GetShadowMap()`函数返回一个连接到该光源的延迟初始化阴影贴图缓冲区:

```
  clPtr<clGLFrameBuffer> iLight::GetShadowMap() const
  {
    if ( !m_ShadowMap )
    {
      m_ShadowMap = make_intrusive<clGLFrameBuffer>();
      m_ShadowMap->InitRenderTargetV(
        { ivec4(1024, 1024, 8, 0) },
        true
      );
    }
    return m_ShadowMap;
  }
```

光源的属性包括其在简单照明模型中使用的漫射和环境颜色、位置和方向以计算观察矩阵和聚光灯锥角:

```
public:
  vec4 m_Ambient;
  vec4 m_Diffuse;
  vec3 m_Position;
  vec3 m_Direction;
  float m_SpotOuterAngle;
```

最后，我们声明一个保存阴影贴图的帧缓冲区:

```
  mutable clPtr<clGLFrameBuffer> m_ShadowMap;
};
```

让我们看看着色器程序的制服是如何更新的。这发生在`UpdateROPUniforms()`中，在渲染每个阴影贴图之前，每个渲染操作都会调用它:

```
void iLight::UpdateROPUniforms( const std::vector<clRenderOp>& ROPs, const clPtr<clMaterialSystem>& MatSys, const clPtr<clLightNode>& LightNode ) const
{
  mat4 LightMV = this->GetViewForShadowMap();
  mat4 LightProj = GetProjectionForShadowMap();
  mat4 Mtx = LightNode->GetGlobalTransformConst();
  vec3 Pos = ( Mtx * vec4( this->m_Position, 1.0f ) ).XYZ();
  vec3 Dir = ( Mtx * vec4( this->m_Direction, 0.0f ) ).XYZ();
  auto AmbientSP = MatSys->GetShaderProgramForPass( ePass_Ambient );
  AmbientSP->Bind();
  AmbientSP->SetUniformNameVec3Array( "u_LightPos", 1, Pos );
  AmbientSP->SetUniformNameVec3Array( "u_LightDir", 1, Dir );
  auto LightSP = MatSys->GetShaderProgramForPass( ePass_Light );
  LightSP->Bind();
  LightSP->SetUniformNameVec3Array( "u_LightPos", 1, Pos );
  LightSP->SetUniformNameVec3Array( "u_LightDir", 1, Dir );
  LightSP->SetUniformNameVec4Array( "u_LightDiffuse", 1, this->m_Diffuse );
  mat4 ScaleBias = GetProjScaleBiasMat();
  mat4 ShadowMatrix = ( Mtx * LightMV * LightProj ) * ScaleBias;
  LightSP->SetUniformNameMat4Array( "in_ShadowMatrix", 1, ShadowMatrix );
  this->GetShadowMap()->GetDepthTexture()->Bind( 0 );
}
```

`GetProjScaleBiasMat()`助手例程返回一个缩放矩阵，该矩阵映射[-1..1]归一化设备坐标到【0..1]范围:

```
mat4 GetProjScaleBiasMat()
{
  return mat4( 0.5f, 0.0f, 0.0f, 0.0f, 0.0f, 0.5f, 0.0f, 0.0f, 0.0f, 0.0f, 0.5f, 0.0f, 0.5f, 0.5f, 0.5f, 1.0 );
}
```

这段代码中提到的`clMaterialSystem`类需要一些额外的解释。

# 物质系统

在我们之前的示例`1_SceneGraphRenderer`中，我们使用了一个着色器程序来渲染场景中的所有对象。现在，我们的渲染器将变成多通道。我们需要创建阴影贴图，然后渲染阴影对象并计算光照。这是在三个不同的渲染过程中使用三个不同的着色器程序完成的。为了区分路径，我们定义`ePass`枚举如下:

```
enum ePass
{
  ePass_Ambient,
  ePass_Light,
  ePass_Shadow
};
```

为了基于通道和材质属性处理不同的着色器程序，我们实现了`clMaterialSystem`类:

```
class clMaterialSystem: public iIntrusiveCounter
{
public:
  clMaterialSystem();
```

`GetShaderProgramForPass()`方法返回存储在`std::map`中的指定过程的着色器程序:

```
  clPtr<clGLSLShaderProgram> GetShaderProgramForPass(ePass P)
  {
    return m_ShaderPrograms[ P ];
  }
private:
  std::map<ePass, clPtr<clGLSLShaderProgram>> m_ShaderPrograms;
};
```

此类的构造函数创建渲染所需的每个着色器程序，并将其插入到地图中:

```
clMaterialSystem::clMaterialSystem()
{
  m_ShaderPrograms[ ePass_Ambient ] = make_intrusive<clGLSLShaderProgram>( g_vShaderStr, g_fShaderAmbientStr );
  m_ShaderPrograms[ ePass_Light   ] = make_intrusive<clGLSLShaderProgram>( g_vShaderStr, g_fShaderLightStr );
  m_ShaderPrograms[ ePass_Shadow  ] = make_intrusive<clGLSLShaderProgram>( g_vShaderShadowStr, g_fShaderShadowStr );
}
```

### 注

在本例中，可以用简单的 C 风格数组替换地图。然而，稍后，我们将在不同的着色器程序中使用不同的材质类型，因此贴图会非常合适。

与前面的示例一样，每个着色器的源代码都存储在一个静态字符串变量中。这一次，代码有点复杂。顶点着色器源代码在环境光和每道光之间共享:

```
static const char g_vShaderStr[] = R"(
  uniform mat4 in_ModelViewProjectionMatrix;
  uniform mat4 in_NormalMatrix;
  uniform mat4 in_ModelMatrix;
  uniform mat4 in_ShadowMatrix;
  in vec4 in_Vertex;
  in vec2 in_TexCoord;
  in vec3 in_Normal;
  out vec2 v_Coords;
  out vec3 v_Normal;
  out vec3 v_WorldNormal;
  out vec4 v_ProjectedVertex;
  out vec4 v_ShadowMapCoord;
```

C++代码中使用了相同的函数来转换[-1..1]到[0..1]范围:

```
  mat4 GetProjScaleBiasMat()
  {
    return mat4( 
      0.5, 0.0, 0.0, 0.0, 
      0.0, 0.5, 0.0, 0.0, 
      0.0, 0.0, 0.5, 0.0, 
      0.5, 0.5, 0.5, 1.0 );
  }
```

值被传递给后续片段着色器:

```
  void main()
  {
    v_Coords = in_TexCoord.xy;
    v_Normal = mat3(in_NormalMatrix) * in_Normal;
    v_WorldNormal = ( in_ModelMatrix * vec4( in_Normal, 0.0 ) ).xyz;
    v_ProjectedVertex = GetProjScaleBiasMat() * in_ModelViewProjectionMatrix * in_Vertex;
    v_ShadowMapCoord = in_ShadowMatrix * in_ModelMatrix * in_Vertex;
    gl_Position = in_ModelViewProjectionMatrix * in_Vertex;
  }
)";
```

这里是环境通道的片段着色器。只需将环境颜色输出到帧缓冲区，我们就完成了:

```
static const char g_fShaderAmbientStr[] = R"(
  in vec2 v_Coords;
  in vec3 v_Normal;
  in vec3 v_WorldNormal;
  out vec4 out_FragColor;
  uniform vec4 u_AmbientColor;
  uniform vec4 u_DiffuseColor;
  void main()
  {
    out_FragColor = u_AmbientColor;
  }
)";
```

每个灯光通道的片段着色器根据灯光参数和阴影贴图计算实际的灯光和阴影。这就是为什么它比我们以前的所有着色器都要长的原因:

```
static const char g_fShaderLightStr[] = R"(
  in vec2 v_Coords;
  in vec3 v_Normal;
  in vec3 v_WorldNormal;
  in vec4 v_ProjectedVertex;
  in vec4 v_ShadowMapCoord;
  out vec4 out_FragColor;
  uniform vec4 u_AmbientColor;
  uniform vec4 u_DiffuseColor;
  uniform vec3 u_LightPos;
  uniform vec3 u_LightDir;
  uniform vec4 u_LightDiffuse;
  uniform sampler2D Texture0;
```

阴影是使用称为*百分比更接近过滤*的技术计算的。如果我们使用一种天真的阴影映射方法，产生的阴影会有很多混叠。 **百分比更接近滤波** ( **PCF** )的想法是从当前像素周围的阴影图中采样，将其深度与所有样本进行比较。通过平均比较的结果(而不是采样的结果)，我们可以获得更平滑的光影边缘。我们的示例使用一个具有 26 个抽头的 5×5 PCF 滤波器:

```
  float PCF5x5( const vec2 ShadowCoord, float Depth )
  {
    float Size = 1.0 / float( textureSize( Texture0, 0 ).x );
    float Shadow =( Depth >= texture( Texture0, ShadowCoord ).r ) ? 1.0 : 0.0;
    for ( int v=-2; v<=2; v++ ) for ( int u=-2; u<=2; u++ )
    {
       Shadow += ( Depth >= texture( Texture0, ShadowCoord + Size * vec2(u, v) ).r ) ? 1.0 : 0.0;
    }
    return Shadow / 26.0;
  }
```

下面是评估给定片段是否处于阴影中的函数:

```
  float ComputeSpotLightShadow()
  {
```

进行透视分割，将阴影贴图投影到对象上:

```
    vec4 ShadowCoords4 = v_ShadowMapCoord / v_ShadowMapCoord.w;
    if ( ShadowCoords4.w > 0.0 )
    {
      vec2 ShadowCoord = vec2( ShadowCoords4 );
      float DepthBias = -0.0002;
      float ShadowSample = 1.0 - PCF5x5( ShadowCoord, ShadowCoords4.z + DepthBias );
```

`DepthBias`系数用于预防阴影痤疮。以下是同一场景的两个渲染图，零`DepthBias`(左)和`-0.0002`(右):

![Material system](../Images/image00226.jpeg)

一般来说，它需要手动调整，应该是光的参数的一部分。查看以下链接，了解更多关于如何改善阴影的想法:

[https://msdn . Microsoft . com/en-us/library/windows/desktop/ee 416324(v = vs . 85)。aspx](https://msdn.microsoft.com/en-us/library/windows/desktop/ee416324(v=vs.85).aspx) 。

现在，将系数相乘并返回结果值:

```
      float ShadowCoef = 0.3;
      return ShadowSample * ShadowCoef;
    }
    return 1.0;
  }
```

现在，我们可以根据实际光线方向及其阴影图计算一个简单的照明模型:

```
  void main()
  {
    vec4 Kd = u_DiffuseColor * u_LightDiffuse;
    vec3 L = normalize( u_LightDir );
    vec3 N = normalize( v_WorldNormal );
    float d = clamp( dot( -L, N ), 0.0, 1.0 );
    vec4 Color = Kd * d * ComputeSpotLightShadow();
    Color.w = 1.0;
    out_FragColor = Color;
  }
)";
```

为了构建在前面的着色器中使用的阴影贴图，我们需要一个额外的渲染过程。对于每个灯光，使用以下顶点和片段着色器:

```
static const char g_vShaderShadowStr[] = R"(
  uniform mat4 in_ModelViewProjectionMatrix;
  in vec4 in_Vertex;
  void main()
  {
    gl_Position = in_ModelViewProjectionMatrix * in_Vertex;
  }
)";
static const char g_fShaderShadowStr[] = R"(
  out vec4 out_FragColor;
  void main()
  {
    out_FragColor = vec4( 1, 1, 1, 1 );
  }
)";
```

现在我们可以用所有阴影和更精确的光照渲染出更好的图像。我们来看看`2_ShadowMaps/main.cpp`文件。

# 演示应用程序和渲染技术

新代码最重要的部分在`OnDrawFrame()`方法中。它使用`clForwardRenderingTechnique`类来渲染场景。让我们来看看`Technique.cpp.`

辅助函数`RenderROPs()`用于渲染渲染操作的矢量:

```
void RenderROPs( sMatrices& Matrices, const std::vector<clRenderOp>& RenderQueue, ePass Pass )
{
  for ( const auto& ROP : RenderQueue )
  {
    ROP.Render( Matrices, g_MatSys, Pass );
  }
}
```

现在，所有的过程都可以用这个函数来描述。看一下功能`clForwardRenderingTechnique::Render()`。首先，让我们为不透明的和透明的对象构建两个渲染队列。透明物体是那些以字符串`Particle`为材质类别的物体。我们将在下一章中使用透明对象:

```
m_TransformUpdateTraverser.Traverse( Root );
m_ROPsTraverser.Traverse( Root );
const auto& RenderQueue = m_ROPsTraverser.GetRenderQueue();
auto RenderQueue_Opaque = Select( RenderQueue, []( const clRenderOp& ROP )
    {
      return ROP.m_Material->GetMaterial().m_MaterialClass != "Particle";
    } );
    auto RenderQueue_Transparent = Select( RenderQueue, []( const clRenderOp& ROP )
    {
      return ROP.m_Material->GetMaterial().m_MaterialClass == "Particle";
    } 
  );
```

为着色器准备矩阵并清除 OpenGL 缓冲区:

```
  sMatrices Matrices;
  Matrices.m_ProjectionMatrix = Proj;
  Matrices.m_ViewMatrix = View;
  Matrices.UpdateMatrices();
  LGL3->glClearColor( 0.0f, 0.0f, 0.0f, 0.0f );
  LGL3->glClear( GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT );
  LGL3->glEnable( GL_DEPTH_TEST );
```

现在，用环境颜色渲染所有对象。就是这样，环境通道不需要任何灯光。作为副产品，我们将有一个充满值的 Z 缓冲区，因此我们可以在后续过程中禁用深度写入:

```
  LGL3->glDepthFunc( GL_LEQUAL );
  LGL3->glDisablei( GL_BLEND, 0 );
  RenderROPs( Matrices, RenderQueue_Opaque, ePass_Ambient, MatSys );
```

对于随后的每道光，我们需要场景中的光矢量。从 traverser 获取并更新所有阴影贴图:

```
  auto Lights = g_ROPsTraverser.GetLights();
  UpdateShadowMaps( Lights, RenderQueue );
```

`UpdateShadowMaps()`函数迭代一个光节点向量，并将阴影投射器渲染成相应的阴影贴图:

```
  void UpdateShadowMaps( const std::vector<clLightNode*>& Lights, const std::vector<clRenderOp>& ROPs )
  {
    LGL3->glDisable( GL_BLEND );
    for ( size_t i = 0; i != Lights.size(); i++ )
    {
      sMatrices ShadowMatrices;
      clPtr<iLight> L = Lights[ i ]->GetLight();
      clPtr<clGLFrameBuffer> ShadowBuffer = L->GetShadowMap();
```

绑定并清除阴影贴图帧缓冲区:

```
      ShadowBuffer->Bind( 0 );
      LGL3->glClearColor( 0, 0, 0, 1 );
      LGL3->glClear( GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT );
```

光知道它的投影和视图矩阵。该代码非常通用，可以扩展到与灯光类型一起使用，包括带有多个观察墩的灯光:

```
      LMatrix4 Proj = L->GetProjectionForShadowMap();
      LMatrix4 MV = L->GetViewForShadowMap();
```

在着色器程序中更新制服:

```
      ShadowMatrices.m_ViewMatrix = MV;
      ShadowMatrices.m_ProjectionMatrix = Proj;
      ShadowMatrices.UpdateMatrices();
      L->UpdateROPUniforms( ROPs, g_MatSys, Lights[i] );
```

渲染到阴影贴图中并取消绑定帧缓冲区:

```
      RenderROPs( ShadowMatrices, ROPs, ePass_Shadow );
      ShadowBuffer->UnBind();
    }
  }
```

所有的阴影贴图现在都可以在渲染代码中使用了。让我们继续`OnDrawFrame()`功能。每道光累积来自所有光源的照明，如下所示:

```
  LGL3->glDepthFunc( GL_EQUAL );
  LGL3->glBlendFunc( GL_ONE, GL_ONE );
  LGL3->glEnablei( GL_BLEND, 0 );
  for ( const auto& L : Lights )
  {
    L->GetLight()->UpdateROPUniforms( RenderQueue, MatSys, L );
    RenderROPs( Matrices, RenderQueue, ePass_Light, MatSys );
  }
```

最后但不是最不重要的，渲染透明对象的环境照明:

```
  LGL3->glBlendFunc(GL_SRC_ALPHA, GL_ONE);
  LGL3->glDepthFunc(GL_LESS);
  LGL3->glEnablei(GL_BLEND, 0);
  LGL3->glDepthMask( GL_FALSE );
  RenderROPs( Matrices, RenderQueue_Transparent, ePass_Ambient, MatSys );
```

别忘了重置 OpenGL 状态。扩展渲染器的一个好方法是将深度测试、深度遮罩、混合模式等状态封装到一个管道状态对象中，并且只在管道状态发生变化时更新它们。如果您想将示例扩展到完整的渲染代码中，这种改进是必须的:

```
  LGL3->glDepthMask( GL_TRUE );
```

我们介绍了所有的低级渲染代码。让我们更上一层楼，看看如何构建一个场景。

## 场景构建

我们的测试场景是在`main()`中构建的，过程如下。首先，全局对象被实例化:

```
  g_MatSys = make_intrusive<clMaterialSystem>();
  g_Scene = make_intrusive<clSceneNode>();
  g_Canvas = make_intrusive<clGLCanvas>( g_Window );
```

之后，设置材料和材料节点:

```
  auto CubeMaterialNode = make_intrusive<clMaterialNode>();
  {
    sMaterial Material;
    Material.m_Ambient = vec4( 0.2f, 0.0f, 0.0f, 1.0f );
    Material.m_Diffuse = vec4( 0.8f, 0.0f, 0.0f, 1.0f );
    CubeMaterialNode->SetMaterial( Material );
  }
  auto PlaneMaterialNode = make_intrusive<clMaterialNode>();
  {
    sMaterial Material;
    Material.m_Ambient = vec4( 0.0f, 0.2f, 0.0f, 1.0f );
    Material.m_Diffuse = vec4( 0.0f, 0.8f, 0.0f, 1.0f );
    PlaneMaterialNode->SetMaterial( Material );
  }
  auto DeimosMaterialNode = make_intrusive<clMaterialNode>();
  {
    sMaterial Material;
    Material.m_Ambient = vec4( 0.0f, 0.0f, 0.2f, 1.0f );
    Material.m_Diffuse = vec4( 0.0f, 0.0f, 0.8f, 1.0f );
    DeimosMaterialNode->SetMaterial( Material );
  }
```

现在，我们可以使用一堆盒子和一个从`.obj`文件加载的戴莫斯 3D 模型(https://en . Wikipedia . org/wiki/戴莫斯 _(月亮))来创建场景的几何图形:

```
  {
    auto VA = clGeomServ::CreateAxisAlignedBox( vec3(-0.5), vec3(+0.5) );
    g_Box= make_intrusive<clGeometryNode>();
    g_Box->SetVertexAttribs( VA );
    CubeMaterialNode->Add( g_Box );
```

该功能可以在`Loader_OBJ.cpp`文件中找到，并对波前 OBJ 文件格式([https://en.wikipedia.org/wiki/Wavefront_.obj_file](https://en.wikipedia.org/wiki/Wavefront_.obj_file))进行解析:

```
    auto DeimosNode = LoadOBJSceneNode( g_FS->CreateReader( "deimos.obj" ) );
    DeimosNode->SetLocalTransform( mat4::GetScaleMatrix(vec3(0.01f, 0.01f, 0.01f)) * mat4::GetTranslateMatrix(vec3(1.1f, 1.1f, 0.0f)) );
    DeimosMaterialNode->Add( DeimosNode );
  }
  {
    auto VA = clGeomServ::CreateAxisAlignedBox( vec3(-2.0f, -2.0f, -1.0f), vec3(2.0f, 2.0f, -0.95f) );
    auto Geometry = make_intrusive<clGeometryNode>();
    Geometry->SetVertexAttribs( VA );
    PlaneMaterialNode->Add( Geometry );
  }
```

最后但同样重要的是，我们将为场景添加两个灯光，这将产生两个不同的阴影:

```
  {
    auto Light = make_intrusive<iLight>( );
    Light->m_Diffuse = vec4( 0.5f, 0.5f, 0.5f, 1.0f );
    Light->m_Position = vec3( 5, 5, 5 );
    Light->m_Direction = vec3( -1, -1, -1 ).GetNormalized();
    Light->m_SpotOuterAngle = 21;
    g_LightNode = make_intrusive<clLightNode>( );
    g_LightNode->SetLight( Light );
    g_Scene->Add( g_LightNode );
  }
  {
    auto Light = make_intrusive<iLight>();
    Light->m_Diffuse = vec4( 0.5f, 0.5f, 0.5f, 1.0f );
    Light->m_Position = vec3( 5, -5, 5 );
    Light->m_Direction = vec3( -1, 1, -1 ).GetNormalized();
    Light->m_SpotOuterAngle = 20;
    auto LightNode = make_intrusive<clLightNode>();
    LightNode->SetLight( Light );
    g_Scene->Add( LightNode );
  }
```

将所有组装在一起，进入应用主循环:

```
  g_Scene->Add( CubeMaterialNode );
  g_Scene->Add( PlaneMaterialNode );
  g_Scene->Add( DeimosMaterialNode );
  while( g_Window && g_Window->HandleInput() )
  {
    OnDrawFrame();
    g_Window->Swap();
  }
```

生成的应用程序使用旋转立方体和来自两个光源的阴影渲染以下图像:

![Scene construction](../Images/image00227.jpeg)

演示应用也可以在安卓上运行。去试试吧！

## 用户与 3D 场景的交互

我们希望您尝试运行`2_ShadowMaps`示例。您可能已经注意到，可以通过触摸屏上的手势或在台式机器上使用鼠标来旋转 3D 场景。

这是使用`clVirtualTrackball`类完成的，该类通过基于提供的触摸点计算视图矩阵来模拟虚拟轨迹球:

```
class clVirtualTrackball
{
public:
  clVirtualTrackball():
  FCurrentPoint( 0.0f ),
  FPrevPoint( 0.0f ),
  FStarted( false )
  {
    FRotation.IdentityMatrix();
    FRotationDelta.IdentityMatrix();
  };
```

获取对应于新触摸点的视图矩阵:

```
  virtual LMatrix4 DragTo( LVector2 ScreenPoint, float Speed, bool KeyPressed )
  {
    if ( KeyPressed && !FStarted )
    {
      StartDragging( ScreenPoint );
      FStarted = KeyPressed;
      return mat4::Identity();
    }
    FStarted = KeyPressed;
```

如果我们没有接触到屏幕，返回一个身份矩阵:

```
    if ( !KeyPressed ) return mat4::Identity();
```

将触摸点投影到虚拟轨迹球球体上，并找出当前投影点和前一个投影点之间的距离:

```
    FCurrentPoint = ProjectOnSphere( ScreenPoint );
    LVector3 Direction = FCurrentPoint - FPrevPoint;
    LMatrix4 RotMatrix;
    RotMatrix.IdentityMatrix();
    float Shift = Direction.Length();
```

如果距离非零，计算并返回旋转矩阵:

```
    if ( Shift > Math::EPSILON )
    {
      LVector3 Axis = FPrevPoint.Cross( FCurrentPoint );
      RotMatrix.RotateMatrixAxis( Shift * Speed, Axis );
    }
    FRotationDelta = RotMatrix;
    return RotMatrix;
  }
  LMatrix4& GetRotationDelta()
  {
    return FRotationDelta;
  };
```

获取当前矩阵:

```
  virtual LMatrix4 GetRotationMatrix() const
  {
    return FRotation * FRotationDelta;
  }
  static clVirtualTrackball* Create()
  {
    return new clVirtualTrackball();
  }
```

当用户第一次触摸屏幕时，重置轨迹球的状态:

```
private:
  virtual void StartDragging( LVector2 ScreenPoint )
  {
    FRotation = FRotation * FRotationDelta;
    FCurrentPoint = ProjectOnSphere( ScreenPoint );
    FPrevPoint = FCurrentPoint;
    FRotationDelta.IdentityMatrix();
  }
```

投影数学是这样的:

```
  LVector3 ProjectOnSphere( LVector2 ScreenPoint )
  {
    LVector3 Proj;
```

将标准化点坐标转换到`-1.0...1.0`范围:

```
    Proj.x = 2.0f * ScreenPoint.x - 1.0f;
    Proj.y = -( 2.0f * ScreenPoint.y - 1.0f );
    Proj.z = 0.0f;
    float Length = Proj.Length();
    Length = ( Length < 1.0f ) ? Length : 1.0f;
    Proj.z = sqrtf( 1.001f - Length * Length );
    Proj.Normalize();
    return Proj;
  }
  LVector3 FCurrentPoint;
  LVector3 FPrevPoint;
  LMatrix4 FRotation;
  LMatrix4 FRotationDelta;
  bool FStarted;
};
```

该类用于`UpdateTrackball()`函数，该函数从`OnDrawFrame()`调用:

```
void UpdateTrackball( float Speed )
{
  g_Trackball.DragTo( g_MouseState.FPos, Speed, g_MouseState.FPressed );
}
void OnDrawFrame()
{
  UpdateTrackball( 10.0f );
  mat4 TrackballMtx = g_Trackball.GetRotationMatrix();
  Matrices.m_ViewMatrix = TrackballMtx * g_Camera.GetViewMatrix();
}
```

该类使您能够在触摸屏上旋转 3D 场景，并用于在设备上调试场景。

# 总结

在本章中，我们学习了如何在独立于平台的 OpenGL 包装器上构建更高级别的场景图抽象。我们可以使用材质和光源创建场景对象，并使用灯光和阴影渲染场景。在下一章中，我们将暂时远离渲染——嗯，不完全是——并学习如何在 C++中实现游戏逻辑。