# 第八章。处理输入设备和传感器

> *安卓全靠交互。诚然，这意味着反馈，通过图形、音频、振动等等。但是没有输入就没有互动！当今智能手机的成功源于其多元化和现代化的输入可能性:触摸屏、键盘、鼠标、全球定位系统、加速度计、光检测器、录音机等。正确处理和组合它们是丰富应用程序并使其成功的关键。*

虽然安卓系统可以处理很多输入外设，但安卓 NDK 系统的支持一直非常有限(至少不说)，直到 R5 的发布！我们现在可以通过本地应用编程接口直接访问它。可用设备的示例有:

*   键盘，物理键盘(带滑出式键盘)或虚拟键盘(显示在屏幕上)
*   方向板(上、下、左、右和动作按钮)，通常缩写为 D-Pad。
*   轨迹球，包括光学的
*   触摸屏使现代智能手机获得了成功
*   鼠标或跟踪板(自 NDK R5 起，但仅适用于蜂窝设备)

我们还可以访问硬件传感器，如下所示:

*   加速度计，用于测量施加到设备上的线性加速度。
*   陀螺仪，测量角速度。它通常与磁力计结合使用，以准确快速地计算方位。陀螺仪是最近才推出的，目前还没有在大多数设备上提供。
*   磁力计，它给出环境磁场，从而给出基本方向。
*   光传感器，例如，自动适应屏幕亮度。
*   例如，接近传感器，用于在通话过程中检测耳朵距离。

除了硬件传感器，姜饼还引入了“软件传感器”。这些传感器来自硬件传感器的数据:

*   重力传感器，用于测量重力方向和大小
*   线性加速度传感器，用于测量除重力之外的设备“运动”
*   旋转矢量，表示设备在空间中的方向

重力传感器和线性加速度传感器源自加速度计。另一方面，旋转矢量是从磁力计和加速计导出的。因为这些传感器通常是随时间计算的，所以它们在获取最新值时通常会稍有延迟。

为了更深入地熟悉输入设备和传感器，本章教我们如何:

*   处理屏幕触摸
*   检测键盘、数字键盘和轨迹球事件
*   将加速计传感器变成游戏手柄

# 与触摸事件交互

当今智能手机最具代表性的创新是触摸屏，它取代了现在的古董鼠标。顾名思义，触摸屏可以检测用手指或触控笔在设备表面进行的触摸。根据屏幕的质量，可以处理几个触摸(在安卓系统中也称为光标)，从而降低交互的可能性。

所以让我们从处理`DroidBlaster`中的触摸事件开始这一章。为了简单起见，我们只处理一次“接触”。目标是将船向接触的方向移动。触摸得越远，船走得越快。超过预定范围`TOUCH_MAX_RANGE`，船速达到限速，如下图所示:

![Interacting with touch events](graphics/9645OS_08_01.jpg)

### 注

由此产生的项目以`DroidBlaster_Part13`的名称提供本书。

# 行动时间-处理触摸事件

让我们截取`DroidBlaster`中的触摸事件:

1.  就像我们在[第 5 章](05.html "Chapter 5. Writing a Fully Native Application")、*中创建`ActivityHandler`来处理应用程序事件一样，编写一个完全原生的应用程序*，创建`jni/InputHandler.hpp`来处理输入事件。输入应用编程接口在`android/input.h`声明。创建`onTouchEvent()`来处理触摸事件。这些事件被包装在一个`AInputEvent`结构中。其他输入外设将在本章后面描述:

    ```
    #ifndef _PACKT_INPUTHANDLER_HPP_
    #define _PACKT_INPUTHANDLER_HPP_

    #include <android/input.h>

    class InputHandler {
    public:
        virtual ~InputHandler() {};

        virtual bool onTouchEvent(AInputEvent* pEvent) = 0;
    };
    #endif
    ```

2.  Modify the `jni/EventLoop.hpp` header file to include and handle an `InputHandler` instance.

    类似地，对于活动事件，定义一个内部方法`processInputEvent()`，由静态回调`callback_input()`触发:

    ```
    ...
    #include "ActivityHandler.hpp"
    #include "InputHandler.hpp"

    #include <android_native_app_glue.h>

    class EventLoop {
    public:
    EventLoop(android_app* pApplication,
                ActivityHandler& pActivityHandler,
                InputHandler& pInputHandler);
        ...
    private:
        ...
        void processAppEvent(int32_t pCommand);
        int32_t processInputEvent(AInputEvent* pEvent);

        static void callback_appEvent(android_app* pApplication,
                int32_t pCommand);
        static int32_t callback_input(android_app* pApplication,
     AInputEvent* pEvent);

        ...
        ActivityHandler& mActivityHandler;
        InputHandler& mInputHandler;
    };
    #endif
    ```

3.  We need to process input events in the `jni/EventLoop.cpp` source file and notify the associated `InputHandler`.

    首先，将安卓输入队列连接到`callback_input()`。`EventLoop`本身(即`this`)通过`android_app`结构的`userData`成员匿名传递。这样，回调能够将输入处理委托回我们自己的对象，即`processInputEvent()`:

    ```
    ...
    EventLoop::EventLoop(android_app* pApplication,
        ActivityHandler& pActivityHandler, InputHandler& pInputHandler):
            mApplication(pApplication),
            mActivityHandler(pActivityHandler),
            mEnabled(false), mQuit(false),
            mInputHandler(pInputHandler) {
        mApplication->userData = this;
        mApplication->onAppCmd = callback_appEvent;
     mApplication->onInputEvent = callback_input;
    }

    ...

    int32_t EventLoop::callback_input(android_app* pApplication,
     AInputEvent* pEvent) {
     EventLoop& eventLoop = *(EventLoop*) pApplication->userData;
     return eventLoop.processInputEvent(pEvent);
    }
    ...
    ```

4.  Touchscreen events are of the type `MotionEvent` (as opposed to key events). They can be discriminated according to their source (`AINPUT_SOURCE_TOUCHSCREEN`) thanks to the Android native input API (here, `AinputEvent_getSource()`):

    ### 注

    注意`callback_input()`和扩展的`processInputEvent()`如何返回整数值(本质上是一个布尔值)。该值表示输入事件(例如，按下的按钮)已由应用程序处理，不需要由系统进一步处理。例如，当按下后退按钮停止事件处理并防止活动终止时，将返回`1`。

    ```
    ...
    int32_t EventLoop::processInputEvent(AInputEvent* pEvent) {
        if (!mEnabled) return 0;

        int32_t eventType = AInputEvent_getType(pEvent);
        switch (eventType) {
        case AINPUT_EVENT_TYPE_MOTION:
            switch (AInputEvent_getSource(pEvent)) {
            case AINPUT_SOURCE_TOUCHSCREEN:
                return mInputHandler.onTouchEvent(pEvent);
                break;
            }
            break;
        }
        return 0;
    }
    ```

5.  Create `jni/InputManager.hpp` to handle touch events and implement our new `InputHandler` interface.

    定义方法如下:

    *   `start()`执行必要的初始化。
    *   `onTouchEvent()`当触发新事件时，更新管理器状态。
    *   `getDirectionX()`和`getDirectionY()`表示船舶方向。
    *   `setRefPoint()`指船的位置。实际上，方向被定义为接触点和船只位置(即参考点)之间的向量。

    此外，声明必要的成员，更具体地说`mScaleFactor`，它包含将输入事件从屏幕坐标转换为游戏坐标的适当比例(请记住，我们使用固定的大小)。

    ```
    #ifndef _PACKT_INPUTMANAGER_HPP_
    #define _PACKT_INPUTMANAGER_HPP_

    #include "GraphicsManager.hpp"
    #include "InputHandler.hpp"
    #include "Types.hpp"

    #include <android_native_app_glue.h>

    class InputManager : public InputHandler {
    public:
        InputManager(android_app* pApplication,
                 GraphicsManager& pGraphicsManager);

        float getDirectionX() { return mDirectionX; };
        float getDirectionY() { return mDirectionY; };
        void setRefPoint(Location* pRefPoint) { mRefPoint = pRefPoint; };

        void start();

    protected:
        bool onTouchEvent(AInputEvent* pEvent);

    private:
        android_app* mApplication;
        GraphicsManager& mGraphicsManager;

        // Input values.
        float mScaleFactor;
        float mDirectionX, mDirectionY;
        // Reference point to evaluate touch distance.
        Location* mRefPoint;
    };
    #endif
    ```

6.  创建 `jni/InputManager.cpp`，从构造函数开始:

    ```
    #include "InputManager.hpp"
    #include "Log.hpp"

    #include <android_native_app_glue.h>
    #include <cmath>

    InputManager::InputManager(android_app* pApplication,
            GraphicsManager& pGraphicsManager) :
        mApplication(pApplication), mGraphicsManager(pGraphicsManager),
        mDirectionX(0.0f), mDirectionY(0.0f),
        mRefPoint(NULL) {
    }
    ...
    ```

7.  写`start()`方法清除成员，计算比例因子。比例因子是必要的，因为正如[第 6 章](06.html "Chapter 6. Rendering Graphics with OpenGL ES")、*用 OpenGL ES 渲染图形*所见，我们需要将输入事件中提供的屏幕坐标(取决于设备)转换为游戏坐标:

    ```
    ...
    void InputManager::start() {
        Log::info("Starting InputManager.");
        mDirectionX = 0.0f, mDirectionY = 0.0f;
        mScaleFactor = float(mGraphicsManager.getRenderWidth())
                           / float(mGraphicsManager.getScreenWidth());
    }
    ...
    ```

8.  The effective event processing comes in `onTouchEvent()`. Horizontal and vertical directions are computed according to the distance between the reference point and the touch point. This distance is restricted by `TOUCH_MAX_RANGE` to an arbitrary range of `65` units. Thus, a ship's maximum speed is reached when the reference-to-touch point distance is beyond `TOUCH_MAX_RANGE` pixels.

    当你移动手指时，由于`AMotionEvent_getX()`和`AMotionEvent_getY()`，触摸坐标被检索。当不再检测到触摸时，方向向量被重置为`0`:

    ```
    ...
    bool InputManager::onTouchEvent(AInputEvent* pEvent) {
        static const float TOUCH_MAX_RANGE = 65.0f; // In game units.

        if (mRefPoint != NULL) {
            if (AMotionEvent_getAction(pEvent)
                            == AMOTION_EVENT_ACTION_MOVE) {
                float x = AMotionEvent_getX(pEvent, 0) * mScaleFactor;
                float y = (float(mGraphicsManager.getScreenHeight())
                         - AMotionEvent_getY(pEvent, 0)) * mScaleFactor;
                // Needs a conversion to proper coordinates
                // (origin at bottom/left). Only moveY needs it.
                float moveX = x - mRefPoint->x;
                float moveY = y - mRefPoint->y;
                float moveRange = sqrt((moveX * moveX) + (moveY * moveY));

                if (moveRange > TOUCH_MAX_RANGE) {
                    float cropFactor = TOUCH_MAX_RANGE / moveRange;
                    moveX *= cropFactor; moveY *= cropFactor;
                }

                mDirectionX = moveX / TOUCH_MAX_RANGE;
                mDirectionY   = moveY / TOUCH_MAX_RANGE;
            } else {
                mDirectionX = 0.0f; mDirectionY = 0.0f;
            }
        }
        return true;
    }
    ```

9.  创建一个简单的组件`jni/MoveableBody.hpp`，其作用是根据输入事件移动`PhysicsBody`:

    ```
    #ifndef _PACKT_MOVEABLEBODY_HPP_
    #define _PACKT_MOVEABLEBODY_HPP_

    #include "InputManager.hpp"
    #include "PhysicsManager.hpp"
    #include "Types.hpp"

    class MoveableBody {
    public:
        MoveableBody(android_app* pApplication,
           InputManager& pInputManager, PhysicsManager& pPhysicsManager);

        PhysicsBody* registerMoveableBody(Location& pLocation,
                int32_t pSizeX, int32_t pSizeY);

        void initialize();
        void update();

    private:
        PhysicsManager& mPhysicsManager;
        InputManager& mInputManager;

        PhysicsBody* mBody;
    };
    #endif
    ```

10.  Implement this component in `jni/MoveableBody.cpp`.

    `InputManager`和身体绑定在`registerMoveableBody()`中:

    ```
    #include "Log.hpp"
    #include "MoveableBody.hpp"

    MoveableBody::MoveableBody(android_app* pApplication,
          InputManager& pInputManager, PhysicsManager& pPhysicsManager) :
        mInputManager(pInputManager),
        mPhysicsManager(pPhysicsManager),
        mBody(NULL) {
    }

    PhysicsBody* MoveableBody::registerMoveableBody(Location& pLocation,
    int32_t pSizeX, int32_t pSizeY) {
        mBody = mPhysicsManager.loadBody(pLocation, pSizeX, pSizeY);
        mInputManager.setRefPoint(&pLocation);
        return mBody;
    }
    ...
    ```

11.  Initially, the body has no velocity.

    然后，每次更新时，速度都会反映当前的输入状态。该速度由[第 5 章](05.html "Chapter 5. Writing a Fully Native Application")*中创建的`PhysicsManager`输入，编写一个完全原生的应用程序*，以更新实体的位置:

    ```
    ...
    void MoveableBody::initialize() {
        mBody->velocityX = 0.0f;
        mBody->velocityY = 0.0f;
    }

    void MoveableBody::update() {
        static const float MOVE_SPEED = 320.0f;
        mBody->velocityX = mInputManager.getDirectionX() * MOVE_SPEED;
        mBody->velocityY = mInputManager.getDirectionY() * MOVE_SPEED;
    }
    ```

    参考`jni/DroidBlaster.hpp`中新增的`InputManager`和`MoveableComponent`:

    ```
    ...
    #include "EventLoop.hpp"
    #include "GraphicsManager.hpp"
    #include "InputManager.hpp"
    #include "MoveableBody.hpp"
    #include "PhysicsManager.hpp"
    #include "Resource.hpp"
    ...

    class DroidBlaster : public ActivityHandler {
        ...
    private:
        TimeManager     mTimeManager;
        GraphicsManager mGraphicsManager;
        PhysicsManager  mPhysicsManager;
        SoundManager    mSoundManager;
        InputManager    mInputManager;
        EventLoop mEventLoop;
        ...
        Asteroid mAsteroids;
        Ship mShip;
        StarField mStarField;
        SpriteBatch mSpriteBatch;
        MoveableBody mMoveableBody;
    };
    #endif
    ```

12.  Finally, adapt the `jni/DroidBlaster.cpp` constructor to instantiate `InputManager` and `MoveableComponent`.

    在构建时，将`InputManager`追加到`EventLoop`中，后者调度输入事件。

    宇宙飞船是被移动的实体。因此，将对其位置的引用传递给`MoveableBody`组件:

    ```
    ...
    DroidBlaster::DroidBlaster(android_app* pApplication):
        mTimeManager(),
        mGraphicsManager(pApplication),
        mPhysicsManager(mTimeManager, mGraphicsManager),
        mSoundManager(pApplication),
        mInputManager(pApplication, mGraphicsManager),
     mEventLoop(pApplication, *this, mInputManager),
        ...
        mAsteroids(pApplication, mTimeManager, mGraphicsManager,
        mPhysicsManager),
        mShip(pApplication, mGraphicsManager, mSoundManager),
        mStarField(pApplication, mTimeManager, mGraphicsManager,
                STAR_COUNT, mStarTexture),
        mSpriteBatch(mTimeManager, mGraphicsManager),
        mMoveableBody(pApplication, mInputManager, mPhysicsManager) {
        ...
        Sprite* shipGraphics = mSpriteBatch.registerSprite(mShipTexture,
                SHIP_SIZE, SHIP_SIZE);
        shipGraphics->setAnimation(SHIP_FRAME_1, SHIP_FRAME_COUNT,
                SHIP_ANIM_SPEED, true);
        Sound* collisionSound =
                mSoundManager.registerSound(mCollisionSound);
        mMoveableBody.registerMoveableBody(shipGraphics->location,
     SHIP_SIZE, SHIP_SIZE);
        mShip.registerShip(shipGraphics, collisionSound);

        // Creates asteroids.
        ...
    }
    ...
    ```

13.  用相应的方法初始化更新`MoveableBody`和`InputManager`:

    ```
    ...
    status DroidBlaster::onActivate() {
        Log::info("Activating DroidBlaster");
        if (mGraphicsManager.start() != STATUS_OK) return STATUS_KO;
        if (mSoundManager.start() != STATUS_OK) return STATUS_KO;
        mInputManager.start();

        mSoundManager.playBGM(mBGM);

        mAsteroids.initialize();
        mShip.initialize();
        mMoveableBody.initialize();

        mTimeManager.reset();
        return STATUS_OK;
    }

    ...

    status DroidBlaster::onStep() {
        mTimeManager.update();
        mPhysicsManager.update();

        mAsteroids.update();
        mMoveableBody.update();

        return mGraphicsManager.update();
    }
    ...
    ```

## *刚刚发生了什么？*

我们基于触摸事件创建了一个简单的输入系统示例。船以取决于接触距离的速度朝着接触点飞行。触摸事件坐标是绝对的。它们的原点在屏幕左上角，在 OpenGL 的对面，也就是左下角。如果应用程序允许屏幕旋转，那么从用户的角度来看，无论设备处于纵向模式还是横向模式，屏幕原点都将保留在左上角。

![What just happened?](graphics/9645OS_08_07.jpg)

为了实现这个新特性，我们将事件循环连接到`native_app_glue`模块提供的输入事件队列。这个队列在内部表示为一个 UNIX 管道，就像活动事件队列一样。触摸屏事件嵌入在`AInputEvent`结构中，该结构存储其他类型的输入事件。输入事件通过在`android/input.h`声明的`AInputEvent`和`AMotionEvent`应用编程接口处理。使用`AInputEvent_getType()`和`AInputEvent_getSource()`方法区分输入事件类型需要`AInputEvent`应用编程接口。`AMotionEvent` API 仅提供方法来处理触摸事件。

触控 API 相当丰富。可以要求许多细节，如下表所示(非详尽):

<colgroup><col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

方法

 | 

描述

 |
| --- | --- |
| 

```
AMotionEvent_getAction()
```

 | 检测手指是否接触屏幕、离开屏幕或在屏幕上移动。结果是一个整数值，由事件类型(在字节`1`上，例如`AMOTION_EVENT_ACTION_DOWN`)和指针索引(在字节`2`上，知道事件指的是哪个手指)组成。 |
| 

```
AMotionEvent_getX()
AMotionEvent_getY()
```

 | 检索屏幕上的触摸坐标，以像素为单位表示为一个浮点数(子像素值是可能的)。 |
| 

```
AMotionEvent_getDownTime()
AMotionEvent_getEventTime()
```

 | 检索手指在屏幕上滑动的时间以及事件的生成时间(以纳秒为单位)。 |
| 

```
AMotionEvent_getPressure()
AMotionEvent_getSize()

```

 | 检测压力强度和区域。数值通常在`0.0`和`1.0`之间(但可能超过)。大小和压力一般密切相关。根据硬件的不同，这种行为可能会有很大的差异，并且会产生噪音。 |
| 

```
AMotionEvent_getHistorySize()
AMotionEvent_getHistoricalX()
AMotionEvent_getHistoricalY()
```

 | 为了提高效率，可以将`AMOTION_EVENT_ACTION_MOVE`类型的触摸事件组合在一起。这些方法提供了这些发生在过去和现在事件之间的历史点。 |

查看`android/input.h`查看方法的详尽列表。

如果你更深入地观察`AMotionEvent` API，你会注意到一些事件有第二个参数`pointer_index`，范围在`0`和活动指针的数量之间。的确，如今大多数触摸屏都是多点触控的！屏幕上的两个或两个以上的手指(如果硬件支持的话)在安卓系统中通过两个或两个以上的指针来翻译。要操作它们，请查看下表:

<colgroup><col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

方法

 | 

描述

 |
| --- | --- |
| 

```
AMotionEvent_getPointerCount()
```

 | 要知道有多少手指触摸屏幕。 |
| 

```
AMotionEvent_getPointerId()
```

 | 从指针索引中获取指针唯一标识符。这是随着时间跟踪特定指针(即*手指*)的唯一方法，因为当手指触摸或离开屏幕时，其索引可能会改变。 |

### 类型

如果你遵循现在史前的(*的故事！* ) Nexus One，那你就知道它出来的时候有硬件缺陷。指针经常混淆，两个指针交换一个坐标。因此，始终准备好处理硬件特性或行为不正确的硬件！

# 检测键盘、数字键盘和轨迹球事件

其中最常见的输入设备是键盘。安卓也是如此。安卓键盘可以是物理键盘:在设备正面(像传统的黑莓手机)或滑出式屏幕上。然而，键盘更常见的是虚拟的，即以占用大量空间为代价在屏幕上模拟。除了键盘本身，每个安卓设备都必须包括一些物理或仿真按钮，如**菜单**、**主页**和**任务**。

一种不太常见的输入设备是方向板。数据板是一组向上、向下、向左或向右移动的物理按钮和一个特定的动作/确认按钮。虽然它们经常从最近的手机和平板电脑中消失，但平板电脑仍然是在文本或用户界面小部件之间移动的最方便的方式之一。d-pad 经常被轨迹球取代。轨迹球的行为类似于倒置的鼠标(里面有球的那种)。一些轨迹球是类比的，但是其他的(例如，光学的)表现为一个 D-Pad(也就是说，全有或全无)。

![Detecting keyboard, D-Pad, and Trackball events](graphics/9645OS_08_02.jpg)

为了了解它们是如何工作的，让我们使用这些外围设备来移动我们的宇宙飞船。安卓 NDK 现在允许在本地端处理所有这些输入外设。所以，让我们试试吧！

### 注

由此产生的项目以`DroidBlaster_Part14`的名称提供本书。

# 行动时间——处理键盘、数字键盘和轨迹球事件

让我们用更多的事件类型来扩展我们的新输入系统:

1.  打开 `jni/InputHandler.hpp`，添加键盘和轨迹球事件处理程序:

    ```
    #ifndef _PACKT_INPUTHANDLER_HPP_
    #define _PACKT_INPUTHANDLER_HPP_

    #include <android/input.h>

    class InputHandler {
    public:
        virtual ~InputHandler() {};

        virtual bool onTouchEvent(AInputEvent* pEvent) = 0;
        virtual bool onKeyboardEvent(AInputEvent* pEvent) = 0;
     virtual bool onTrackballEvent(AInputEvent* pEvent) = 0;
    };
    #endif
    ```

2.  Update the method `processInputEvent()` inside the existing file `jni/EventLoop.cpp` to redirect the keyboard and trackball events to `InputHandler`.

    轨迹球和触摸事件类似于运动事件，可以根据它们的来源进行区分。另一方面，关键事件根据其类型进行区分。的确，有两个专用的 API 分别用于`MotionEvents`(轨迹球和触摸事件相同)和`KeyEvents`(键盘、数字键盘等相同):

    ```
    ...
    int32_t EventLoop::processInputEvent(AInputEvent* pEvent) {
        if (!mEnabled) return 0;

        int32_t eventType = AInputEvent_getType(pEvent);
        switch (eventType) {
        case AINPUT_EVENT_TYPE_MOTION:
            switch (AInputEvent_getSource(pEvent)) {
            case AINPUT_SOURCE_TOUCHSCREEN:
                return mInputHandler.onTouchEvent(pEvent);
                break;

            case AINPUT_SOURCE_TRACKBALL:
     return mInputHandler.onTrackballEvent(pEvent);
     break;
            }
            break;

        case AINPUT_EVENT_TYPE_KEY:
     return mInputHandler.onKeyboardEvent(pEvent);
     break;
        }
    return 0;
    }
    ...
    ```

3.  修改的`jni/InputManager.hpp`文件以覆盖这些新方法:

    ```
    ...
    class InputManager : public InputHandler {
        ...
    protected:
        bool onTouchEvent(AInputEvent* pEvent);
        bool onKeyboardEvent(AInputEvent* pEvent);
     bool onTrackballEvent(AInputEvent* pEvent);

        ...
    };
    #endif
    ```

4.  In `jni/InputManager.cpp`, process the keyboard events in `onKeyboardEvent()` using:
    *   `AKeyEvent_getAction()`获取事件类型(即按下与否)。
    *   `AKeyEvent_getKeyCode()`获取按钮身份。

    在下面的代码中，当按下左、右、上或下按钮时，`InputManager`计算方向并将其保存到`mDirectionX`和`mDirectionY`中。按钮按下时运动开始，按下时停止。

    钥匙用完时返回`true`，钥匙没用完时返回`false`。事实上，如果一个用户已经按下了，例如，背部按钮(`AKEYCODE_BACK`)或音量按钮(`AKEYCODE_VOLUME_UP`、`AKEYCODE_VOLUME_DOWN`)，那么我们让系统为我们适当地反应:

    ```
    ...
    bool InputManager::onKeyboardEvent(AInputEvent* pEvent) {
        static const float ORTHOGONAL_MOVE = 1.0f;

        if (AKeyEvent_getAction(pEvent) == AKEY_EVENT_ACTION_DOWN) {
            switch (AKeyEvent_getKeyCode(pEvent)) {
            case AKEYCODE_DPAD_LEFT:
                mDirectionX = -ORTHOGONAL_MOVE;
                return true;
            case AKEYCODE_DPAD_RIGHT:
                mDirectionX = ORTHOGONAL_MOVE;
                return true;
            case AKEYCODE_DPAD_DOWN:
                mDirectionY = -ORTHOGONAL_MOVE;
                return true;
            case AKEYCODE_DPAD_UP:
                mDirectionY = ORTHOGONAL_MOVE;
                return true;
            }
        } else {
            switch (AKeyEvent_getKeyCode(pEvent)) {
            case AKEYCODE_DPAD_LEFT:
            case AKEYCODE_DPAD_RIGHT:
                mDirectionX = 0.0f;
                return true;
            case AKEYCODE_DPAD_DOWN:
            case AKEYCODE_DPAD_UP:
                mDirectionY = 0.0f;
                return true;
            }
        }
        return false;
    }
    ...
    ```

5.  同样，用新方法`onTrackballEvent()`处理轨迹球事件。用`AMotionEvent_getX()`和`AMotionEvent_getY()`检索轨迹球大小。因为一些轨迹球不提供渐变的幅度，所以运动用简单的常数量化。通过任意触发阈值忽略可能的噪声:

    ```
    ...
    bool InputManager::onTrackballEvent(AInputEvent* pEvent) {
        static const float ORTHOGONAL_MOVE = 1.0f;
        static const float DIAGONAL_MOVE   = 0.707f;
        static const float THRESHOLD       = (1/100.0f);

         if (AMotionEvent_getAction(pEvent) == AMOTION_EVENT_ACTION_MOVE) {
            float directionX = AMotionEvent_getX(pEvent, 0);
            float directionY = AMotionEvent_getY(pEvent, 0);
            float horizontal, vertical;

            if (directionX < -THRESHOLD) {
                if (directionY < -THRESHOLD) {
                    horizontal = -DIAGONAL_MOVE;
                    vertical   = DIAGONAL_MOVE;
                } else if (directionY > THRESHOLD) {
                    horizontal = -DIAGONAL_MOVE;
                    vertical   = -DIAGONAL_MOVE;
                } else {
                    horizontal = -ORTHOGONAL_MOVE;
                    vertical   = 0.0f;
                }
            } else if (directionX > THRESHOLD) {
                if (directionY < -THRESHOLD) {
                    horizontal = DIAGONAL_MOVE;
                    vertical   = DIAGONAL_MOVE;
                } else if (directionY > THRESHOLD) {
                    horizontal = DIAGONAL_MOVE;
                    vertical   = -DIAGONAL_MOVE;
                } else {
                    horizontal = ORTHOGONAL_MOVE;
                    vertical   = 0.0f;
                }
            } else if (directionY < -THRESHOLD) {
                horizontal = 0.0f;
                vertical   = ORTHOGONAL_MOVE;
            } else if (directionY > THRESHOLD) {
                horizontal = 0.0f;
                vertical   = -ORTHOGONAL_MOVE;
            }
    ...
    ```

6.  当以这种方式使用轨迹球时，船只移动直到“反向移动”(例如，向左移动时请求向右移动)或按下动作按钮(最后一个`else`部分):

    ```
            ...
            // Ends movement if there is a counter movement.
            if ((horizontal < 0.0f) && (mDirectionX > 0.0f)) {
                mDirectionX = 0.0f;
            } else if ((horizontal > 0.0f) && (mDirectionX < 0.0f)) {
                mDirectionX = 0.0f;
            } else {
                mDirectionX = horizontal;
            }

            if ((vertical < 0.0f) && (mDirectionY > 0.0f)) {
                mDirectionY = 0.0f;
            } else if ((vertical > 0.0f) && (mDirectionY < 0.0f)) {
                mDirectionY = 0.0f;
            } else {
                mDirectionY = vertical;
            }
        } else {
            mDirectionX = 0.0f; mDirectionY = 0.0f;
        }
        return true;
    }
    ```

## *刚刚发生了什么？*

我们扩展了我们的输入系统来处理键盘、键盘和轨迹球事件。D-Pad 可以被认为是的一个键盘扩展，并且是以同样的方式处理的。事实上，D-Pad 和键盘事件是在同一个结构中传输的(`AInputEvent`)并由同一个 API 处理(前缀为`AKeyEvent`)。

下表列出了主要的关键事件方法:

<colgroup><col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

方法

 | 

描述

 |
| --- | --- |
| `AKeyEvent_getAction()` | 指示按钮是按下(`AKEY_EVENT_ACTION_DOWN`)还是松开(`AKEY_EVENT_ACTION_UP`)。注意，可以批量发出多个关键动作(`AKEY_EVENT_ACTION_MULTIPLE`)。 |
| `AKeyEvent_getKeyCode()` | 检索实际被按下的按钮(在`android/keycodes.h`中定义)，例如，左按钮的`AKEYCODE_DPAD_LEFT`。 |
| `AKeyEvent_getFlags()` | 按键事件可以与一个或多个标志相关联，这些标志给出关于事件的各种信息，例如源自仿真键盘的事件的`AKEY_EVENT_LONG_PRESS`、`AKEY_EVENT_FLAG_SOFT_KEYBOARD`。 |
| `AKeyEvent_getScanCode()` | 是否类似于密钥代码，除了这是原始密钥 ID，依赖于不同的设备，并且因设备而异。 |
| `AKeyEvent_getMetaState()` | Meta 状态是指示某些修饰键(如 Alt 或 Shift)是否被同时按下的标志(如`AMETA_SHIFT_ON`、`AMETA_NONE`等)。 |
| `AKeyEvent_getRepeatCount()` | 指示按钮事件发生了多少次，通常是当您按下按钮时。 |
| `AKeyEvent_getDownTime()` | 要知道什么时候按了一个按钮。 |

虽然它们中的一些(尤其是光学的)表现得像一个 D-Pad，但是轨迹球并不使用相同的 API。实际上，轨迹球是通过`AMotionEvent` API 处理的(比如触摸事件)。当然，为触摸事件提供的一些信息并不总是在轨迹球上可用。最重要的功能如下:

<colgroup><col style="text-align: left"> <col style="text-align: left"></colgroup> 
| `AMotionEvent_getAction()` | 了解事件是否代表移动动作(与按压动作相对)。 |
| `AMotionEvent_getX()``AMotionEvent_getY()` | 到获取轨迹球的移动。 |
| `AKeyEvent_getDownTime()` | 到知道轨迹球是否被按下(如 D-Pad 动作按钮)。目前，大多数轨迹球使用全有或全无的压力来指示新闻事件。 |

处理轨迹球时需要记住的一个棘手问题是，没有生成任何事件来指示轨迹球没有移动。此外，轨迹球事件是作为“突发”生成的，这使得更难检测到运动何时结束。除了使用手动计时器并定期检查足够长时间内没有事件发生之外，没有简单的方法来处理这个问题。

### 类型

永远不要期望外设在所有手机上的表现完全相同。轨迹球就是一个很好的例子；它们可以像模拟垫一样指示方向，也可以像数字垫一样指示直线方向(例如，光学轨迹球)。目前没有办法区分设备特性和可用的 API。唯一的解决方案是校准设备或在运行时配置设备，或者保存一种设备数据库。

# 探测设备传感器

处理输入设备对任何应用来说都是必不可少的，但是探测传感器对最聪明的应用来说很重要！安卓游戏应用中分布最广的传感器是加速度计。

顾名思义，加速度计测量施加到设备上的线性加速度。当向上、向下、向左或向右移动设备时，加速度计会受到激励，并指示三维空间中的加速度矢量。矢量是相对于屏幕的默认方向来表示的。坐标系相对于设备的自然方向:

*   x 轴指向右侧
*   y 点向上
*   z 从后向前指向

如果设备旋转，轴会反转(例如，如果设备顺时针旋转 90 度，Y 点会向左)。

加速度计的一个非常有趣的特征是它们经历一个恒定的加速度:重力，在地球上约为 9.8m/s2。例如，当平躺在桌子上时，加速度矢量在 Z 轴上指示-9.8。直线时，它在 Y 轴上表示相同的值。因此，假设设备位置是固定的，设备在两个空间轴上的方向可以从重力加速度矢量中推导出来。仍然需要磁力计来获得 3D 空间中的全部设备方向。

### 类型

请记住，加速度计与线性加速度一起工作。它们允许检测设备不旋转时的平移和设备固定时的部分定向。然而，如果没有磁力计和/或陀螺仪，这两种运动是无法结合的。

因此，我们可以使用从加速度计推导出的设备方向来计算方向。现在让我们看看如何在`DroidBlaster`中应用这个过程。

### 注

由此产生的项目以`DroidBlaster_Part15`的名称提供本书。

# 行动时间-处理加速计事件

让我们在 `DroidBlaster`中处理加速度计事件:

1.  打开`jni/InputHandler.hpp`添加新方法`onAccelerometerEvent()`。包括传感器的`android/sensor.h`官方标题:

    ```
    #ifndef _PACKT_INPUTHANDLER_HPP_
    #define _PACKT_INPUTHANDLER_HPP_

    #include <android/input.h>
    #include <android/sensor.h>

    class InputHandler {
    public:
        virtual ~InputHandler() {};

        virtual bool onTouchEvent(AInputEvent* pEvent) = 0;
        virtual bool onKeyboardEvent(AInputEvent* pEvent) = 0;
        virtual bool onTrackballEvent(AInputEvent* pEvent) = 0;
        virtual bool onAccelerometerEvent(ASensorEvent* pEvent) = 0;
    };
    #endif
    ```

2.  Create new methods in `jni/EventLoop.hpp`:
    *   `activateAccelerometer()`和`deactivateAccelerometer()`在活动开始和停止时启用/禁用加速计传感器。
    *   `processSensorEvent()`检索和调度传感器事件。
    *   回调`callback_input()`静态方法绑定到 Looper。

    另外，定义以下成员:

    *   `ASensorManager`类型的`mSensorManager`是与传感器交互的主要“对象”。
    *   `mSensorEventQueue`是`ASensorEventQueue`，这是传感器应用编程接口定义的一个结构，用于检索发生的事件。
    *   `mSensorPollSource`是原生胶中定义的`android_poll_source`。这个结构描述了如何将本地线程 Looper 绑定到传感器回调。
    *   宣布为`ASensor`结构的`mAccelerometer`代表使用的传感器:

        ```
        #ifndef _PACKT_EVENTLOOP_HPP_
        #define _PACKT_EVENTLOOP_HPP_

        #include "ActivityHandler.hpp"
        #include "InputHandler.hpp"

        #include <android_native_app_glue.h>

        class EventLoop {
            ...
        private:
            void activate();
            void deactivate();
            void activateAccelerometer();
         void deactivateAccelerometer();

            void processAppEvent(int32_t pCommand);
            int32_t processInputEvent(AInputEvent* pEvent);
            void processSensorEvent();

            static void callback_appEvent(android_app* pApplication,
                    int32_t pCommand);
            static int32_t callback_input(android_app* pApplication,
                    AInputEvent* pEvent);
            static void callback_sensor(android_app* pApplication,
         android_poll_source* pSource);

            ...
            InputHandler& mInputHandler;

            ASensorManager* mSensorManager;
         ASensorEventQueue* mSensorEventQueue;
         android_poll_source mSensorPollSource;
         const ASensor* mAccelerometer;
        };
        #endif
        ```

3.  更新建造师初始化`jni/EventLoop.cpp`中的列表:

    ```
    #include "EventLoop.hpp"
    #include "Log.hpp"

    EventLoop::EventLoop(android_app* pApplication,
        ActivityHandler& pActivityHandler, InputHandler& pInputHandler):
            mApplication(pApplication),
            mActivityHandler(pActivityHandler),
            mEnabled(false), mQuit(false),
            mInputHandler(pInputHandler),
            mSensorPollSource(), mSensorManager(NULL),
            mSensorEventQueue(NULL), mAccelerometer(NULL) {
        mApplication->userData = this;
        mApplication->onAppCmd = callback_appEvent;
        mApplication->onInputEvent = callback_input;
    }
    ...
    ```

4.  Create the sensor event queue, through which all `sensor` events are notified.

    绑定到`callback_sensor()`。请注意，我们使用本机应用程序胶水提供的`LOOPER_ID_USER`常量来附加用户定义的队列。

    然后，调用`activateAccelerometer()`初始化加速度计传感器:

    ```
    ...
    void EventLoop::activate() {
        if ((!mEnabled) && (mApplication->window != NULL)) {
            mSensorPollSource.id = LOOPER_ID_USER;
     mSensorPollSource.app = mApplication;
     mSensorPollSource.process = callback_sensor;
     mSensorManager = ASensorManager_getInstance();
     if (mSensorManager != NULL) {
     mSensorEventQueue = ASensorManager_createEventQueue(
     mSensorManager, mApplication->looper,
     LOOPER_ID_USER, NULL, &mSensorPollSource);
     if (mSensorEventQueue == NULL) goto ERROR;
     }
     activateAccelerometer();

            mQuit = false; mEnabled = true;
            if (mActivityHandler.onActivate() != STATUS_OK) {
                goto ERROR;
            }
        }
        return;

    ERROR:
        mQuit = true;
        deactivate();
        ANativeActivity_finish(mApplication->activity);
    }
    ...
    ```

5.  When an activity is disabled or terminated, disable the running accelerometer to avoid consuming battery needlessly.

    然后，破坏`sensor`事件队列:

    ```
    ...
    void EventLoop::deactivate() {
        if (mEnabled) {
            deactivateAccelerometer();
     if (mSensorEventQueue != NULL) {
     ASensorManager_destroyEventQueue(mSensorManager,
     mSensorEventQueue);
     mSensorEventQueue = NULL;
     }
     mSensorManager = NULL;

            mActivityHandler.onDeactivate();
            mEnabled = false;
        }
    }
    ...
    ```

6.  当轮询事件循环时，`callback_sensor()`被触发。它将事件调度到`EventLoop`实例上的`processSensorEvent()`。我们只关心`ASENSOR_TYPE_ACCELEROMETER`事件:

    ```
    ...
    void EventLoop::callback_sensor(android_app* pApplication,
        android_poll_source* pSource) {
        EventLoop& eventLoop = *(EventLoop*) pApplication->userData;
        eventLoop.processSensorEvent();
    }

    void EventLoop::processSensorEvent() {
        ASensorEvent event;
        if (!mEnabled) return;

        while (ASensorEventQueue_getEvents(mSensorEventQueue,
                &event, 1) > 0) {
            switch (event.type) {
            case ASENSOR_TYPE_ACCELEROMETER:
                mInputHandler.onAccelerometerEvent(&event);
                break;
            }
        }
    }
    ...
    ```

7.  Activate the sensor in `activateAccelerometer()` in three main steps:
    *   用`AsensorManager_getDefaultSensor()`获取特定类型的传感器。
    *   然后，用`ASensorEventQueue_enableSensor()`将其启用，以便传感器事件队列中充满相关事件。
    *   使用`ASensorEventQueue_setEventRate()`设置所需的事件率。对于游戏，我们通常希望测量接近实时。可以通过`ASensor_getMinDelay()`查询最小延迟(将其设置为较低的值可能会导致失败)。

    显然，我们应该仅在传感器事件队列准备就绪时执行该设置:

    ```
    ...
    void EventLoop::activateAccelerometer() {
        mAccelerometer = ASensorManager_getDefaultSensor(
                mSensorManager, ASENSOR_TYPE_ACCELEROMETER);
        if (mAccelerometer != NULL) {
            if (ASensorEventQueue_enableSensor(
                    mSensorEventQueue, mAccelerometer) < 0) {
                Log::error("Could not enable accelerometer");
                return;
            }

            int32_t minDelay = ASensor_getMinDelay(mAccelerometer);
            if (ASensorEventQueue_setEventRate(mSensorEventQueue,
                    mAccelerometer, minDelay) < 0) {
                Log::error("Could not set accelerometer rate");
            }
        } else {
            Log::error("No accelerometer found");
        }
    }
    ...
    ```

8.  传感器停用更容易，只需要调用方法`AsensorEventQueue_disableSensor()` :

    ```
    ...
    void EventLoop::deactivateAccelerometer() {
        if (mAccelerometer != NULL) {
            if (ASensorEventQueue_disableSensor(mSensorEventQueue,
                    mAccelerometer) < 0) {
                Log::error("Error while deactivating sensor.");
            }
            mAccelerometer = NULL;
        }
    }
    ```

## *刚刚发生了什么？*

我们创建了一个事件队列来监听传感器事件。事件被包装在`android/sensor.h`中定义的`ASensorEvent`结构中。该结构提供了以下功能:

*   传感器事件起源，即哪个传感器产生了这个事件。
*   传感器事件发生时间。
*   传感器输出值。该值存储在一个联合结构中，也就是说，您可以使用任何一个内部结构(这里，我们对`acceleration`向量感兴趣)。

    ```
    typedef struct ASensorEvent {
        int32_t version;
        int32_t sensor;
        int32_t type;
        int32_t reserved0;
        int64_t timestamp;
        union {
            float           data[16];
            ASensorVector   vector;
            ASensorVector   acceleration;
            ASensorVector   magnetic;
            float           temperature;
            float           distance;
            float           light;
            float           pressure;
        };
        int32_t reserved1[4];
    } ASensorEvent;
    ```

相同的`ASensorEvent`结构用于任何安卓传感器。在加速度计的情况下，我们检索具有三个坐标`x`、`y`和`z`的向量，每个轴一个:

```
typedef struct ASensorVector {
    union {
        float v[3];
        struct {
            float x;
            float y;
            float z;
        };
        struct {
            float azimuth;
            float pitch;
            float roll;
        };
    };
    int8_t status;
    uint8_t reserved[3];
} ASensorVector;
```

在我们的示例中，加速度计设置为尽可能低的事件率，这可能因设备而异。需要注意的是，传感器事件率对电池节省有直接影响！因此，使用一个足以满足您的应用的速率。`ASensor` API 提供了一些查询可用传感器及其能力的方法，如`ASensor_getName()`、`ASensor_getVendor()`、`ASensor_getMinDelay()`等。

现在我们可以检索传感器事件，让我们使用它们来计算船只的方向。

# 该行动了——把安卓设备变成游戏手柄

让我们找到设备方位并正确确定方向。

1.  Write a new file `jni/Configuration.hpp` to help us get device information, and more specifically device rotation (defined as `screen_rot`).

    宣布`findRotation()`在 JNI 的帮助下发现设备方位:

    ```
    #ifndef _PACKT_CONFIGURATION_HPP_
    #define _PACKT_CONFIGURATION_HPP_

    #include "Types.hpp"

    #include <android_native_app_glue.h>
    #include <jni.h>

    typedef int32_t screen_rot;

    const screen_rot ROTATION_0   = 0;
    const screen_rot ROTATION_90  = 1;
    const screen_rot ROTATION_180 = 2;
    const screen_rot ROTATION_270 = 3;

    class Configuration {
    public:
        Configuration(android_app* pApplication);

        screen_rot getRotation() { return mRotation; };

    private:
        void findRotation(JNIEnv* pEnv);

        android_app* mApplication;
        screen_rot mRotation;
    };
    #endif
    ```

2.  Retrieve configuration details in `jni/Configuration.cpp`.

    首先，在构造器中，使用`AConfiguration` API 转储配置属性，如当前语言、国家、屏幕大小、屏幕方向。这些信息可能很有趣，但不足以正确分析加速度计事件:

    ```
    #include "Configuration.hpp"
    #include "Log.hpp"

    #include <stdlib.h>

    Configuration::Configuration(android_app* pApplication) :
        mApplication(pApplication),
        mRotation(0) {
        AConfiguration* configuration = AConfiguration_new();
        if (configuration == NULL) return;

        int32_t result;
        char i18NBuffer[] = "__";
        static const char* orientation[] = {
            "Unknown", "Portrait", "Landscape", "Square"
        };
        static const char* screenSize[] = {
            "Unknown", "Small", "Normal", "Large", "X-Large"
        };
        static const char* screenLong[] = {
            "Unknown", "No", "Yes"
        };

        // Dumps current configuration.
        AConfiguration_fromAssetManager(configuration,
            mApplication->activity->assetManager);
        result = AConfiguration_getSdkVersion(configuration);
        Log::info("SDK Version : %d", result);
        AConfiguration_getLanguage(configuration, i18NBuffer);
        Log::info("Language    : %s", i18NBuffer);
        AConfiguration_getCountry(configuration, i18NBuffer);
        Log::info("Country     : %s", i18NBuffer);
        result = AConfiguration_getOrientation(configuration);
        Log::info("Orientation : %s (%d)", orientation[result], result);
        result = AConfiguration_getDensity(configuration);
        Log::info("Density     : %d dpi", result);
        result = AConfiguration_getScreenSize(configuration);
        Log::info("Screen Size : %s (%d)", screenSize[result], result);
        result = AConfiguration_getScreenLong(configuration);
        Log::info("Long Screen : %s (%d)", screenLong[result], result);
        AConfiguration_delete(configuration);
    ...
    ```

    然后，将当前本机线程附加到安卓虚拟机。

    ### 类型

    如果您已经仔细阅读了[第 4 章](04.html "Chapter 4. Calling Java Back from Native Code")、*从本机代码*调用 Java 回调，您就知道这一步是访问`JNIEnv`对象(它是线程特定的)所必需的。`JavaVM`本身可以从`android_app`结构中检索。

3.  After that, call `findRotation()` to retrieve the current device rotation.

    最后，我们可以从达尔维克分离线程，因为我们将不再使用 JNI。请记住，在终止应用程序之前，应始终断开连接的线程:

    ```
    ...
        JavaVM* javaVM = mApplication->activity->vm;
        JavaVMAttachArgs javaVMAttachArgs;
        javaVMAttachArgs.version = JNI_VERSION_1_6;
        javaVMAttachArgs.name = "NativeThread";
        javaVMAttachArgs.group = NULL;
        JNIEnv* env;
        if (javaVM->AttachCurrentThread(&env,
                        &javaVMAttachArgs) != JNI_OK) {
            Log::error("JNI error while attaching the VM");
            return;
        }
        // Finds screen rotation and get-rid of JNI.
        findRotation(env);
        mApplication->activity->vm->DetachCurrentThread();
    }
    ...
    ```

4.  Implement `findRotation()`, which basically executes the following Java code through JNI:

    ```
    WindowManager mgr = (InputMethodManager)
    myActivity.getSystemService(Context.WINDOW_SERVICE);
    int rotation = mgr.getDefaultDisplay().getRotation();
    ```

    显然，在 JNI 写这个稍微复杂一些。

    *   首先，检索 JNI 类，然后检索方法，最后检索字段
    *   然后，执行 JNI 呼叫
    *   最后，发布分配的 JNI 参考

    为了避免额外的检查(即`FindClass()`和`GetMethodID()`对每个方法调用进行返回值和异常检查)，以下代码被自动简化:

    ```
    ...
    void Configuration::findRotation(JNIEnv* pEnv) {
        jobject WINDOW_SERVICE, windowManager, display;
        jclass ClassActivity, ClassContext;
        jclass ClassWindowManager, ClassDisplay;
        jmethodID MethodGetSystemService;
        jmethodID MethodGetDefaultDisplay;
        jmethodID MethodGetRotation;
        jfieldID FieldWINDOW_SERVICE;

        jobject activity = mApplication->activity->clazz;

        // Classes.
        ClassActivity = pEnv->GetObjectClass(activity);
        ClassContext = pEnv->FindClass("android/content/Context");
        ClassWindowManager = pEnv->FindClass(
            "android/view/WindowManager");
        ClassDisplay = pEnv->FindClass("android/view/Display");

        // Methods.
        MethodGetSystemService = pEnv->GetMethodID(ClassActivity,
            "getSystemService",
            "(Ljava/lang/String;)Ljava/lang/Object;");
        MethodGetDefaultDisplay = pEnv->GetMethodID(
            ClassWindowManager, "getDefaultDisplay",
            "()Landroid/view/Display;");
        MethodGetRotation = pEnv->GetMethodID(ClassDisplay,
            "getRotation", "()I");

        // Fields.
        FieldWINDOW_SERVICE = pEnv->GetStaticFieldID(
          ClassContext, "WINDOW_SERVICE", "Ljava/lang/String;");

        // Retrieves Context.WINDOW_SERVICE.
        WINDOW_SERVICE = pEnv->GetStaticObjectField(ClassContext,
            FieldWINDOW_SERVICE);
        // Runs getSystemService(WINDOW_SERVICE).
        windowManager = pEnv->CallObjectMethod(activity,
            MethodGetSystemService, WINDOW_SERVICE);
        // Runs getDefaultDisplay().getRotation().
        display = pEnv->CallObjectMethod(windowManager,
            MethodGetDefaultDisplay);
        mRotation = pEnv->CallIntMethod(display, MethodGetRotation);

        pEnv->DeleteLocalRef(ClassActivity);
        pEnv->DeleteLocalRef(ClassContext);
        pEnv->DeleteLocalRef(ClassWindowManager);
        pEnv->DeleteLocalRef(ClassDisplay);
    }
    ```

5.  Manage the new accelerometer sensor in `jni/InputManager.hpp`.

    加速度计轴在`toScreenCoord()`中转换。

    这个变换意味着我们跟踪设备旋转:

    ```
    ...
    #include "Configuration.hpp"
    #include "GraphicsManager.hpp"
    #include "InputHandler.hpp"
    ...
    class InputManager : public InputHandler {
        ...
    protected:
        bool onTouchEvent(AInputEvent* pEvent);
        bool onKeyboardEvent(AInputEvent* pEvent);
        bool onTrackballEvent(AInputEvent* pEvent);
        bool onAccelerometerEvent(ASensorEvent* pEvent);
     void toScreenCoord(screen_rot pRotation,
     ASensorVector* pCanonical, ASensorVector* pScreen);

    private:
        ...
        float mScaleFactor;
        float mDirectionX, mDirectionY;
         // Reference point to evaluate touch distance.
         Location* mRefPoint;
        screen_rot mRotation;
    };
    #endif
    ```

6.  在`jni/InputManager.hpp`中，借助新的`Configuration`类读取当前屏幕旋转设置。由于`DroidBlaster`强制肖像模式，我们可以一劳永逸地储存旋转:

    ```
    ...
     InputManager::InputManager(android_app* pApplication,
             GraphicsManager& pGraphicsManager) :
            mApplication(pApplication), mGraphicsManager(pGraphicsManager),
            mDirectionX(0.0f), mDirectionY(0.0f),
            mRefPoint(NULL) {
        Configuration configuration(pApplication);
     mRotation = configuration.getRotation();
    }
    ...
    ```

7.  Let's compute a direction from the accelerometer sensor values.

    首先，将加速度计值从标准坐标转换为屏幕坐标，以处理纵向和横向设备。

    然后，根据捕获的加速度计值计算方向。在下面的代码中，`X`和`Z`轴分别表示横摇和纵摇。检查两个轴，设备是处于中性方向(即`CENTER_X`和`CENTER_Z`)还是倾斜方向(`MIN_X`、`MIN_Z`、`MAX_X`和`MAX_Z`)。请注意，Z 值需要根据我们的需要进行反转:

    ```
    ...
    bool InputManager::onAccelerometerEvent(ASensorEvent* pEvent) {
        static const float GRAVITY =  ASENSOR_STANDARD_GRAVITY / 2.0f;
        static const float MIN_X = -1.0f; static const float MAX_X = 1.0f;
        static const float MIN_Z =  0.0f; static const float MAX_Z = 2.0f;
        static const float CENTER_X = (MAX_X + MIN_X) / 2.0f;
        static const float CENTER_Z = (MAX_Z + MIN_Z) / 2.0f;

        // Converts from canonical to screen coordinates.
        ASensorVector vector;
        toScreenCoord(mRotation, &pEvent->vector, &vector);

        // Roll tilt.
        float rawHorizontal = pEvent->vector.x / GRAVITY;
        if (rawHorizontal > MAX_X) {
            rawHorizontal = MAX_X;
        } else if (rawHorizontal < MIN_X) {
            rawHorizontal = MIN_X;
        }
        mDirectionX = CENTER_X - rawHorizontal;

        // Pitch tilt. Final value needs to be inverted.
        float rawVertical = pEvent->vector.z / GRAVITY;
        if (rawVertical > MAX_Z) {
            rawVertical = MAX_Z;
        } else if (rawVertical < MIN_Z) {
            rawVertical = MIN_Z;
        }
        mDirectionY = rawVertical - CENTER_Z;
        return true;
    }
    ...
    ```

8.  在`toScreenCoord()`助手中，根据屏幕旋转来交换或反转加速计轴，以便`X`和`Z`轴指向相同的方向，无论您在人像模式下玩`DroidBlaster`时使用什么设备:

    ```
    ...
    void InputManager::toScreenCoord(screen_rot pRotation,
        ASensorVector* pCanonical, ASensorVector* pScreen) {
        struct AxisSwap {
            int8_t negX; int8_t negY;
            int8_t xSrc; int8_t ySrc;
        };
        static const AxisSwap axisSwaps[] = {
             {  1, -1, 0, 1},  // ROTATION_0
             { -1, -1, 1, 0},  // ROTATION_90
             { -1,  1, 0, 1},  // ROTATION_180
             {  1,  1, 1, 0}}; // ROTATION_270
        const AxisSwap& swap = axisSwaps[pRotation];

        pScreen->v[0] = swap.negX * pCanonical->v[swap.xSrc];
        pScreen->v[1] = swap.negY * pCanonical->v[swap.ySrc];
        pScreen->v[2] = pCanonical->v[2];
    }
    ```

## *刚刚发生了什么？*

加速度计现在是一个游戏手柄！安卓设备可以自然地面向人像(主要是智能手机和较小的平板电脑)，也可以面向风景(主要是平板电脑)。这对接收加速度计事件的应用有影响。轴在这些类型的设备之间的对齐方式不同，取决于它们的旋转方式。

的确，屏幕可以以四种不同的方式定向:`0`、`90`、`180`和`270`度。0 度是设备的自然方位。加速度计的 X 轴总是指向右侧，Y 轴指向上方，Z 轴指向前方。在手机上，Y 指向纵向模式，而在大多数桌子上，Y 指向横向模式。当设备定向为 90 度时，轴的方向明显改变(X 指向上，依此类推)。这种情况也可能发生在纵向模式下使用的平板电脑上(其中 0 度对应于横向模式)。

![What just happened?](graphics/9645OS_08_03.jpg)

遗憾的是，没有办法通过本机应用编程接口获得设备相对于屏幕自然方向的旋转。因此，我们需要依靠 JNI 来获得准确的设备旋转。然后，我们可以很容易地从这个推导出一个方向向量，就像在`onAccelerometerEvent()`中所做的那样。

## 关于传感器的更多信息

每个安卓传感器都有一个唯一的标识符，在`android/sensor.h`中定义。这些标识符在所有安卓设备上都是相同的:

*   `ASENSOR_TYPE_ACCELEROMETER`
*   `ASENSOR_TYPE_MAGNETIC_FIELD`
*   `ASENSOR_TYPE_GYRISCOPE`
*   `ASENSOR_TYPE_LIGHT`
*   `ASENSOR_TYPE_PROXIMITY`

其他传感器可能存在并且可用，即使它们没有在`android/sensor.h`标题中命名。关于姜饼，我们有同样的情况:

*   重力传感器(标识符`9`)
*   线性加速度传感器(标识符`10`)
*   旋转矢量(标识符`11`)。

旋转矢量传感器是现在被否决的方向矢量的后继传感器，在`Augmented Reality`应用中至关重要。它为您提供三维空间中的设备方向。结合全球定位系统，它允许通过你的设备的眼睛定位任何物体。旋转传感器提供了一个数据向量，由于`android.hardware.SensorManager`类(见其源代码)，它可以被转换成一个 OpenGL 视图矩阵。这样，您可以直接将设备方向具体化为屏幕内容，将现实生活和虚拟生活联系在一起。

# 总结

在本章中，我们介绍了从本机代码与安卓交互的多种方式。更准确地说，我们发现了如何将输入队列附加到`Native App Glue`事件循环中。然后，我们处理触摸事件，并处理键盘和触摸板的按键事件或轨迹球的运动事件。最后，我们把加速计变成了一个游戏手柄。

由于安卓的碎片化，期待输入设备行为的特殊性，并准备好调整你的代码。在应用程序结构、图形、声音、输入和传感器方面，我们已经在安卓 NDK 的能力方面做得很好了。然而，重新发明轮子不是解决办法！

在下一章中，我们将通过将现有的 C/C++库移植到安卓系统来释放 NDK 的真正力量。