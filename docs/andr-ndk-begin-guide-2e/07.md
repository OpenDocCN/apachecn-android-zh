# 七、使用 OpenSL ES 播放声音

> *多媒体不仅仅是图形，也是声音和音乐。这个领域的应用是安卓市场最受欢迎的应用之一。事实上，音乐一直是移动设备销售的强劲引擎，音乐爱好者是首选目标。这就是为什么像安卓这样的操作系统没有音乐天赋可能走不远的原因！嵌入式系统开放声音库，更常见的叫 OpenSL ES，是 OpenGL 的声音挂件。尽管级别相当低，但它是所有声音相关任务的一流应用编程接口，无论是输入还是输出。*

在安卓系统上谈论声音时，我们应该区分 Java 和原生世界。事实上，双方的 API 完全不同:一方面是 **MediaPlayer** 、 **SoundPool** 、 **AudioTrack** 、**jetpayer**，另一方面是 **OpenSL ES** :

*   MediaPlayer 更高水平，好用。它不仅处理音乐，还处理视频。当一个简单的文件回放就足够了，这就是我们要走的路。
*   SoundPool 和 AudioTrack 在播放声音时更低级别，更接近低延迟。AudioTrack 是最灵活的，但使用起来也很复杂。它允许动态修改声音缓冲区(手动！).
*   JetPlayer 更多的是专用于 MIDI 文件的播放。这个应用编程接口对于多媒体应用或游戏中的动态音乐合成很有意思(参见安卓软件开发工具包提供的 JetBoy 示例)。
*   OpenSL ES 旨在提供一个跨平台的 API 来管理嵌入式系统上的音频；换句话说，用于音频的 OpenGL ES。像 GLES 一样，它的规格是由 Khronos 集团领导的。在安卓系统上，OpenSL ES 实际上是在 AudioTrack API 之上实现的。

OpenSL ES 最早是在 Android 2.3 姜饼上发布的，在之前的版本(Android 2.2 及更低版本)中是没有的。虽然 Java 中有大量的 API，但 OpenSL ES 是唯一一个在本机端提供的 API，并且只在本机端提供。

但是，OpenSL ES 还不成熟。OpenSL 规范仍未得到完全支持，预计会有一些限制。此外，虽然 1.1 版本已经推出，但 OpenSL 规范是在安卓 1.0.1 版本中实现的。因此，由于 OpenSL ES 实现仍在发展中，未来可能会有一些突破性的变化。

3D 音频功能通过 OpenSL ES 仅适用于系统编译有适当配置文件的设备。事实上，当前的 OpenSL ES 规范为不同类型的设备提供了三种不同的配置文件，游戏、音乐和电话。在撰写本书时，这些配置文件都不受支持。

但是，OpenSL ES 有质量。首先，它可能更容易集成到本机应用的架构中，因为它本身是用 C/C++ 编写的。它不需要背着一个垃圾收集器。本机代码不会被解释，可以通过汇编代码进行深度优化。这些是考虑它的许多理由中的一些。

本章介绍了安卓 NDK 系统上的 OpenSL ES 的音乐功能。我们即将发现如何做到以下几点:

*   在安卓上初始化 OpenSL ES
*   播放背景音乐
*   使用声音缓冲队列播放声音
*   录制声音并播放

音频，更具体地说，实时音频是一门高度技术性的学科。本章涵盖了在您自己的应用中嵌入声音和音乐的基础知识。

# 初始化 OpenSL ES

如果我们不首先初始化它，OpenSL 将不会非常有用。像往常一样，这一步需要一些样板代码。OpenSL 的冗长并没有改善这种情况。让我们从创建一个新的`SoundManager`来包装 OpenSL ES 相关的逻辑开始这一章。

### 注

由此产生的项目以`DroidBlaster_Part10`的名称提供本书。

# 行动时间-创建 OpenSL ES 引擎和输出

让我们创建一个专门处理声音的新经理:

1.  Create a new file `jni/SoundManager.hpp`.

    首先，包含 OpenSL ES 标准头`SLES/OpenSLES.h`。后两者定义了对象和方法，是专门为 Android 创建的。然后，创建`SoundManager`类来执行以下操作:

    *   用`start()`方法初始化 OpenSL ES
    *   停止声音，用`stop()`方法释放 OpenSL ES

    在 OpenSL ES 中有两种主要的伪对象结构(即包含应用于结构本身的函数指针，如带有这个的 C++ 对象):

    *   **对象**:这些用`SLObjectItf`表示，提供了一些常用的获取分配资源和对象接口的方法。这可以粗略地比作 Java 中的一个对象。
    *   **界面**:这些提供了对对象特征的访问。一个对象可以有多个接口。根据主机设备的不同，某些接口可能可用，也可能不可用。这些非常粗略地与 Java 中的接口相当。

    在`SoundManager`中，声明两个`SLObjectItf`实例，一个用于 OpenSL ES 引擎，另一个用于扬声器。发动机可通过`SLEngineItf`界面获得:

    ```cpp
    #ifndef _PACKT_SoundManager_HPP_
    #define _PACKT_SoundManager_HPP_

    #include "Types.hpp"

    #include <android_native_app_glue.h>
    #include <SLES/OpenSLES.h>

    class SoundManager {
    public:
        SoundManager(android_app* pApplication);

        status start();
        void stop();

    private:
        android_app* mApplication;

        SLObjectItf mEngineObj; SLEngineItf mEngine;
        SLObjectItf mOutputMixObj;
    };
    #endif
    ```

2.  用其构造函数

    ```cpp
    #include "Log.hpp"
    #include "Resource.hpp"
    #include "SoundManager.hpp"

    SoundManager::SoundManager(android_app* pApplication) :
        mApplication(pApplication),
        mEngineObj(NULL), mEngine(NULL),
        mOutputMixObj(NULL) {
        Log::info("Creating SoundManager.");
    }
    ...
    ```

    在`jni/SoundManager.cpp`中实现`SoundManager`
3.  编写方法`start()`，它将创建一个 OpenSL Engine 对象和一个`Output Mix`对象。我们需要为每个对象初始化三个变量:
    *   每个对象支持的接口数量(`engineMixIIDCount`和`outputMixIIDCount`)。
    *   所有接口对象的数组应该支持(`engineMixIIDs`和`outputMixIIDs`，例如引擎的`SL_IID_ENGINE`。
    *   一个布尔值数组，指示接口对于程序来说是必需的还是可选的(`engineMixReqs`和`outputMixReqs`)。

        ```cpp
        ...
        status SoundManager::start() {
            Log::info("Starting SoundManager.");
            SLresult result;
            const SLuint32      engineMixIIDCount = 1;
            const SLInterfaceID engineMixIIDs[]   = {SL_IID_ENGINE};
            const SLboolean     engineMixReqs[]   = {SL_BOOLEAN_TRUE};
            const SLuint32      outputMixIIDCount = 0;
            const SLInterfaceID outputMixIIDs[]   = {};
            const SLboolean     outputMixReqs[]   = {};
            ...
        ```

4.  继续方法`start()`:
    *   用`slCreateEngine()`方法初始化 OpenSL ES 引擎对象(即基本类型`SLObjectItf`)。当我们创建一个 OpenSL ES 对象时，我们将要使用的特定接口必须被指明。在这里，我们请求`SL_IID_ENGINE`界面，它允许创建其他 OpenSL ES 对象。引擎是 OpenSL ES API 的中心对象。
    *   然后，在引擎对象上调用`Realize()`。任何 OpenSL ES 对象在使用前都需要*实现*来分配所需的内部资源。
    *   最后，检索`SLEngineItf`-具体界面。
    *   引擎界面为我们提供了用`CreateOutputMix()`方法实例化音频输出混音的可能性。这里定义的音频输出混音将声音传送到默认扬声器。它是自主的(播放的声音会自动发送到扬声器)，所以这里不需要请求任何特定的接口。

        ```cpp
            ...
            // Creates OpenSL ES engine and dumps its capabilities.
            result = slCreateEngine(&mEngineObj, 0, NULL,
                engineMixIIDCount, engineMixIIDs, engineMixReqs);
            if (result != SL_RESULT_SUCCESS) goto ERROR;
            result = (*mEngineObj)->Realize(mEngineObj,SL_BOOLEAN_FALSE);
            if (result != SL_RESULT_SUCCESS) goto ERROR;
            result = (*mEngineObj)->GetInterface(mEngineObj, SL_IID_ENGINE,
                &mEngine);
            if (result != SL_RESULT_SUCCESS) goto ERROR;

            // Creates audio output.
            result = (*mEngine)->CreateOutputMix(mEngine, &mOutputMixObj,
                outputMixIIDCount, outputMixIIDs, outputMixReqs);
            result = (*mOutputMixObj)->Realize(mOutputMixObj,
                SL_BOOLEAN_FALSE);

            return STATUS_OK;

        ERROR:
            Log::error("Error while starting SoundManager");
            stop();
            return STATUS_KO;
        }
        ...
        ```

5.  写`stop()`法摧毁`start()`中已经创造的东西:

    ```cpp
    ...
    void SoundManager::stop() {
        Log::info("Stopping SoundManager.");

        if (mOutputMixObj != NULL) {
            (*mOutputMixObj)->Destroy(mOutputMixObj);
            mOutputMixObj = NULL;
        }
        if (mEngineObj != NULL) {
            (*mEngineObj)->Destroy(mEngineObj);
            mEngineObj = NULL; mEngine = NULL;
        }
    }
    ```

6.  编辑 `jni/DroidBlaster.hpp`并嵌入我们的新 `SoundManager` :

    ```cpp
    ...
    #include "Resource.hpp"
    #include "Ship.hpp"
    #include "SoundManager.hpp"
    #include "SpriteBatch.hpp"
    #include "StarField.hpp"
    ...

    class DroidBlaster : public ActivityHandler {
        ...
    private:
        TimeManager     mTimeManager;
        GraphicsManager mGraphicsManager;
        PhysicsManager  mPhysicsManager;
        SoundManager    mSoundManager;
        EventLoop mEventLoop;

        ...
    };
    #endif
    ```

7.  在`jni/DroidBlaster.cpp` :

    ```cpp
    ...
    DroidBlaster::DroidBlaster(android_app* pApplication):
        mTimeManager(),
        mGraphicsManager(pApplication),
        mPhysicsManager(mTimeManager, mGraphicsManager),
        mSoundManager(pApplication),
        mEventLoop(pApplication, *this),
        ...
        mShip(pApplication, mTimeManager, mGraphicsManager) {
        ...
    }

    ...

    status DroidBlaster::onActivate() {
        Log::info("Activating DroidBlaster");

        if (mGraphicsManager.start() != STATUS_OK) return STATUS_KO;
        if (mSoundManager.start() != STATUS_OK) return STATUS_KO;

        mAsteroids.initialize();
        ...
    }

    void DroidBlaster::onDeactivate() {
        Log::info("Deactivating DroidBlaster");
        mGraphicsManager.stop();
        mSoundManager.stop();
    }
    ```

    中创建、启动和停止声音服务
8.  最后，将文件中的链接到`libOpenSLES.so`:

    ```cpp
    ...
    LS_CPP=$(subst $(1)/,,$(wildcard $(1)/*.cpp))
    LOCAL_MODULE := droidblaster
    LOCAL_SRC_FILES := $(call LS_CPP,$(LOCAL_PATH))
    LOCAL_LDLIBS := -landroid -llog -lEGL -lGLESv2 -lOpenSLES
    LOCAL_STATIC_LIBRARIES := android_native_app_glue png
    ...
    ```

## *刚刚发生了什么？*

运行应用并检查没有记录错误。我们初始化了 OpenSL ES 库，它让我们可以直接从本机代码中访问高效的声音处理原语。除了初始化之外，当前代码不执行任何操作。扬声器还没有发出声音。

这里 OpenSL ES 的入口点是`SLEngineItf`，主要是一个 OpenSL ES 对象工厂。它可以创建到输出设备(扬声器或任何其他设备)的通道，以及声音播放器或录音机(甚至更多！)，我们将在本章后面部分看到。

`SLOutputMixItf`是表示音频输出的对象。通常，这将是设备扬声器或耳机。尽管 OpenSL ES 规范允许枚举可用的输出(以及输入)设备，但 NDK 的实现还不够成熟，无法获得或选择合适的设备(`SLAudioIODeviceCapabilitiesItf`，获取此类信息的官方界面)。因此，在处理输出和输入设备选择时(目前只需要指定记录仪的输入设备)，最好坚持默认值，`SL_DEFAULTDEVICEID_AUDIOINPUT`和`SLES/OpenSLES.h`中定义的`SL_DEFAULTDEVICEID_AUDIOOUTPUT`。

当前的安卓 NDK 实现只允许每个应用有一个引擎(这应该不是问题)，最多允许 32 个创建的对象。但是，请注意，任何对象的创建都可能失败，因为这取决于可用的系统资源。

## 更多关于 OpenSL ES 哲学的内容

OpenSL ES 与它的图形同胞 GLES 不同，部分原因是它并没有很长的历史可以承载。它或多或少是建立在基于对象和接口的面向对象原则上的。以下定义来自官方规范:

*   一个**对象**是一组资源的抽象，分配给一组定义明确的任务，以及这些资源的状态。对象的类型由它的创建决定。对象类型决定了对象可以执行的任务集。这可以被认为类似于 C++ 中的一个类。
*   **界面**是特定对象提供的一组相关特征的抽象。接口包括一组方法，这些方法是接口的功能。接口也有一个类型，它决定了接口的确切方法集。我们可以将接口本身定义为它的类型和与之相关的对象的组合。
*   一个**接口标识**标识一个接口类型。这个标识符在源代码中用来引用接口类型。

OpenSL 专家系统对象的设置步骤如下:

1.  通过构建方法(通常属于引擎)实例化它。
2.  实现它来分配必要的资源。
3.  正在检索对象接口。一个基本对象只有非常有限的一组操作(`Realize()`、`Resume()`、`Destroy()`等等)。界面提供了对真实对象特征的访问，并描述了可以对对象执行的操作，例如`Play`界面播放或暂停声音。

可以请求任何接口，但只有对象支持的接口才能被成功检索。你不能检索音频播放器的录音界面，因为它返回(有时令人恼火！)`SL_RESULT_FEATURE_UNSUPPORTED`(错误代码 12)。用技术术语来说，OpenSL ES 接口是一种包含函数指针(由 OpenSL ES 实现初始化)的结构，带有模拟 C++ 对象的自参数和`this`，例如:

```cpp
struct SLObjectItf_ {
    SLresult (*Realize) (SLObjectItf self, SLboolean async);
    SLresult (*Resume) ( SLObjectItf self, SLboolean async);
    ...
}
```

这里，`Realize()`、`Resume()`等是可以应用于`SLObjectItf`对象的对象方法。接口的方法是相同的。

有关 OpenSL ES 能提供什么的更多详细信息，请参考 Khronos 网站[http://www.khronos.org/opensles](http://www.khronos.org/opensles)上的规范，以及安卓 NDK 文档目录中的 OpenSL ES 文档。安卓实现并不完全尊重规范，至少目前是这样。因此，当发现只有规范的有限子集(尤其是示例代码)在 Android 上工作时，不要失望。

# 播放音乐文件

OpenSL ES 是初始化的，但是扬声器里唯一出来的就是寂静！那么找一首好听的**背景音乐** ( **BGM** )用安卓 NDK 原生播放怎么样？OpenSL ES 提供了必要的东西来读取音乐文件，比如 MP3 文件。

### 注

由此产生的项目以`DroidBlaster_Part11`的名称提供本书。

# 行动时间-播放背景音乐

让我们用 OpenSL ES 打开并播放一个 MP3 音乐文件:

1.  MP3 文件由 OpenSL 使用指向所选文件的 POSIX 文件描述符打开。通过定义一个新的结构`ResourceDescriptor`并附加一个新的方法`descriptor()` :

    ```cpp
    ...
    struct ResourceDescriptor {
     int32_t mDescriptor;
     off_t mStart;
     off_t mLength;
    };

    class Resource {
    public:
        ...
        status open();
        void close();
        status read(void* pBuffer, size_t pCount);

        ResourceDescriptor descriptor();

        bool operator==(const Resource& pOther);

    private:
        ...
    };
    #endif
    ```

    来改进前面章节中创建的`jni/ResourceManager.cpp`
2.  执行`jni/ResourceManager.cpp`。当然，利用素材管理器应用编程接口打开描述符并填充一个`ResourceDescriptor`结构:

    ```cpp
    ...
    ResourceDescriptor Resource::descriptor() {
        ResourceDescriptor lDescriptor = { -1, 0, 0 };
        AAsset* lAsset = AAssetManager_open(mAssetManager, mPath,
                                            AASSET_MODE_UNKNOWN);
        if (lAsset != NULL) {
            lDescriptor.mDescriptor = AAsset_openFileDescriptor(
                lAsset, &lDescriptor.mStart, &lDescriptor.mLength);
            AAsset_close(lAsset);
        }
        return lDescriptor;
    }
    ...
    ```

3.  Go back to `jni/SoundManager.hpp` and define two methods `playBGM()` and `stopBGM()` to play/stop a background MP3 file.

    为音乐播放器声明一个 OpenSL ES 对象，以及以下接口:

    *   `SLPlayItf`播放和停止音乐文件
    *   `SLSeekItf`控制位置和循环

        ```cpp
        ...
        #include <android_native_app_glue.h>
        #include <SLES/OpenSLES.h>
        #include <SLES/OpenSLES_Android.h>

        class SoundManager {
        public:
            ...
            status start();
            void stop();

            status playBGM(Resource& pResource);
         void stopBGM();

        private:
            ...
            SLObjectItf mEngineObj; SLEngineItf mEngine;
            SLObjectItf mOutputMixObj;

            SLObjectItf mBGMPlayerObj; SLPlayItf mBGMPlayer;
         SLSeekItf mBGMPlayerSeek;
        };
        #endif
        ```

4.  Start implementing `jni/SoundManager.cpp`.

    包括`Resource.hpp`以访问素材文件描述符。

    在构造器中初始化新成员并更新`stop()`自动停止背景音乐(不然有些用户会不高兴的！):

    ```cpp
    #include "Log.hpp"
    #include "Resource.hpp"
    #include "SoundManager.hpp"

    SoundManager::SoundManager(android_app* pApplication) :
        mApplication(pApplication),
        mEngineObj(NULL), mEngine(NULL),
        mOutputMixObj(NULL),
        mBGMPlayerObj(NULL), mBGMPlayer(NULL), mBGMPlayerSeek(NULL) {
        Log::info("Creating SoundManager.");
    }

    ...

    void SoundManager::stop() {
        Log::info("Stopping SoundManager.");
        stopBGM();

        if (mOutputMixObj != NULL) {
            (*mOutputMixObj)->Destroy(mOutputMixObj);
            mOutputMixObj = NULL;
        }
        if (mEngineObj != NULL) {
            (*mEngineObj)->Destroy(mEngineObj);
            mEngineObj = NULL; mEngine = NULL;
        }
    }
    ...
    ```

5.  Implement `playBGM()` to enrich the manager with playback features.

    首先，通过两个主要结构`SLDataSource`和`SLDataSink`描述我们的音频设置。第一个描述音频输入通道，第二个描述音频输出通道。

    在这里，我们将数据源配置为 MIME 源，以便从文件描述符中自动检测文件类型。文件描述符当然是通过调用`ResourceManager::descriptor()`打开的。

    数据接收器(即目的通道)在初始化 OpenSL ES 引擎时配置了本章第一部分创建的`OutputMix`对象(并参考默认音频输出，即扬声器或耳机):

    ```cpp
    ...
    status SoundManager::playBGM(Resource& pResource) {
        SLresult result;
        Log::info("Opening BGM %s", pResource.getPath());

        ResourceDescriptor descriptor = pResource.descriptor();
        if (descriptor.mDescriptor < 0) {
            Log::info("Could not open BGM file");
            return STATUS_KO;
        }

        SLDataLocator_AndroidFD dataLocatorIn;
        dataLocatorIn.locatorType = SL_DATALOCATOR_ANDROIDFD;
        dataLocatorIn.fd          = descriptor.mDescriptor;
        dataLocatorIn.offset      = descriptor.mStart;
        dataLocatorIn.length      = descriptor.mLength;

        SLDataFormat_MIME dataFormat;
        dataFormat.formatType    = SL_DATAFORMAT_MIME;
        dataFormat.mimeType      = NULL;
        dataFormat.containerType = SL_CONTAINERTYPE_UNSPECIFIED;

        SLDataSource dataSource;
        dataSource.pLocator = &dataLocatorIn;
        dataSource.pFormat  = &dataFormat;

        SLDataLocator_OutputMix dataLocatorOut;
        dataLocatorOut.locatorType = SL_DATALOCATOR_OUTPUTMIX;
        dataLocatorOut.outputMix   = mOutputMixObj;

        SLDataSink dataSink;
        dataSink.pLocator = &dataLocatorOut;
        dataSink.pFormat  = NULL;
    ...
    ```

6.  然后，创建 OpenSL ES 音频播放器。和往常一样，使用 OpenSL ES 对象，先通过引擎实例化，然后实现。两个接口`SL_IID_PLAY`和`SL_IID_SEEK`是必需的:

    ```cpp
    ...
        const SLuint32 bgmPlayerIIDCount = 2;
        const SLInterfaceID bgmPlayerIIDs[] =
            { SL_IID_PLAY, SL_IID_SEEK };
        const SLboolean bgmPlayerReqs[] =
            { SL_BOOLEAN_TRUE, SL_BOOLEAN_TRUE };

        result = (*mEngine)->CreateAudioPlayer(mEngine,
            &mBGMPlayerObj, &dataSource, &dataSink,
            bgmPlayerIIDCount, bgmPlayerIIDs, bgmPlayerReqs);
        if (result != SL_RESULT_SUCCESS) goto ERROR;
        result = (*mBGMPlayerObj)->Realize(mBGMPlayerObj,
            SL_BOOLEAN_FALSE);
        if (result != SL_RESULT_SUCCESS) goto ERROR;

        result = (*mBGMPlayerObj)->GetInterface(mBGMPlayerObj,
            SL_IID_PLAY, &mBGMPlayer);
        if (result != SL_RESULT_SUCCESS) goto ERROR;
        result = (*mBGMPlayerObj)->GetInterface(mBGMPlayerObj,
            SL_IID_SEEK, &mBGMPlayerSeek);
        if (result != SL_RESULT_SUCCESS) goto ERROR;
    ...
    ```

7.  最后，使用`play``seek`界面，从曲目开始(即`0`毫秒)到结束(`SL_TIME_UNKNOWN`)切换循环模式播放(即音乐继续播放)，然后开始播放(`SetPlayState()``SL_PLAYSTATE_PLAYING`)。

    ```cpp
    ...
        result = (*mBGMPlayerSeek)->SetLoop(mBGMPlayerSeek,
            SL_BOOLEAN_TRUE, 0, SL_TIME_UNKNOWN);
        if (result != SL_RESULT_SUCCESS) goto ERROR;
        result = (*mBGMPlayer)->SetPlayState(mBGMPlayer,
            SL_PLAYSTATE_PLAYING);
        if (result != SL_RESULT_SUCCESS) goto ERROR;

        return STATUS_OK;

    ERROR:
        Log::error("Error playing BGM");
        return STATUS_KO;
    }
    ...
    ```

8.  用最后一种方法`stopBGM()`终止，停止并消灭玩家:

    ```cpp
    ...
    void SoundManager::stopBGM() {
        if (mBGMPlayer != NULL) {
            SLuint32 bgmPlayerState;
            (*mBGMPlayerObj)->GetState(mBGMPlayerObj,
                &bgmPlayerState);
            if (bgmPlayerState == SL_OBJECT_STATE_REALIZED) {
                (*mBGMPlayer)->SetPlayState(mBGMPlayer,
                    SL_PLAYSTATE_PAUSED);

                (*mBGMPlayerObj)->Destroy(mBGMPlayerObj);
                mBGMPlayerObj = NULL;
                mBGMPlayer = NULL; mBGMPlayerSeek = NULL;
            }
        }
    }
    ```

9.  添加指向`jni/DroidBlaster.hpp` :

    ```cpp
    ...
    class DroidBlaster : public ActivityHandler {
        ...
    private:
        ...
        Resource mAsteroidTexture;
        Resource mShipTexture;
        Resource mStarTexture;
        Resource mBGM;
        ...
    };
    #endif
    ```

    中音乐文件的资源
10.  最后，在`jni/DroidBlaster.cpp`中，在`SoundManager`开始后立即开始播放音乐:

    ```cpp
    ...
    DroidBlaster::DroidBlaster(android_app* pApplication):
        ...
        mAsteroidTexture(pApplication, "droidblaster/asteroid.png"),
        mShipTexture(pApplication, "droidblaster/ship.png"),
        mStarTexture(pApplication, "droidblaster/star.png"),
        mBGM(pApplication, "droidblaster/bgm.mp3"),
        ...
        mSpriteBatch(mTimeManager, mGraphicsManager) {
        ...
    }
    ...
    status DroidBlaster::onActivate() {
        Log::info("Activating DroidBlaster");

        if (mGraphicsManager.start() != STATUS_OK) return STATUS_KO;
        if (mSoundManager.start() != STATUS_OK) return STATUS_KO;
        mSoundManager.playBGM(mBGM);

        mAsteroids.initialize();
        mShip.initialize();

        mTimeManager.reset();
        return STATUS_OK;
    }
    ...
    ```

将一个 MP3 文件复制到`droidblaster`的`assets`目录中，并命名为`bgm.mp3`。

### 注

BGM 文件在`DroidBlaster_Part11/assets`目录中随本书提供。

## *刚刚发生了什么？*

我们发现了如何播放 MP3 文件中的音乐片段。回放循环，直到游戏结束。使用 MIME 数据源时，会自动检测文件类型。姜饼目前支持几种格式，包括 Wave PCM、Wave alaw、Wave ulaw、MP3、Ogg Vorbis 等等。当前不支持 MIDI 播放。更多信息请看`$ANDROID_NDK/docs/opensles/index.html`。

这里展示的示例代码是 OpenSL ES 的典型工作方式。OpenSL ES 引擎对象，基本上是一个对象工厂，创建一个`AudioPlayer`。在原始状态下，这个对象做不了什么。首先，需要实现分配必要的资源。然而，这还不够。它需要检索正确的界面，如`SL_IID_PLAY`界面，将音频播放器状态更改为播放/停止。那么，OpenSL API 就可以得到有效的利用。

考虑到结果验证(因为任何调用都容易失败)，这是相当大的工作量，这种工作会使代码变得混乱。进入这个应用编程接口可能比平时多花一点时间，但是一旦理解了，这些概念就变得相当容易处理。

你可能会惊讶地看到`startBGM()`和`stopBGM()`分别重现和破坏了音频播放器。原因是目前没有办法在不完全重新创建 OpenSL ES `AudioPlayer`对象的情况下更改 MIME 数据源。所以这个手法虽然可以播放长片段，但是不适合动态播放短音。

# 播放声音

展示的从 MIME 源播放 BGM 的技术非常实用，但遗憾的是不够灵活。重新创建一个`AudioPlayer`对象是没有必要的，每次访问素材文件在效率上是不好的。

因此，当需要快速播放声音以响应事件并动态生成声音时，我们需要使用声音缓冲队列。每个声音都被预加载或生成在内存缓冲区中，并在请求回放时被放入队列中。运行时不需要访问文件！

一个声音缓冲区，在目前的 OpenSL ES 安卓实现中，可以包含 PCM 数据。**脉码调制** ( **PCM** )是一种专用于表示数字声音的数据格式。这是在光盘和一些波形文件中使用的格式。PCM 可以是单声道(所有扬声器的声音相同)或立体声(如果可用，左右扬声器的声音不同)。

PCM 没有压缩，在存储方面效率不高(只需将音乐光盘与装满 MP3 的数据光盘进行比较)。然而，这种格式是无损的，并提供了最好的质量。质量取决于采样率:模拟声音以数字形式表示为声音信号的一系列度量(即`sample`)。

44100 赫兹的声音样本(即每秒 44100 次测量)具有更好的质量，但也比 16000 赫兹的声音样本发生得更多。此外，每种度量都可以用或多或少的精确程度(编码)来表示。在当前的安卓实现上:

*   声音可以用 8000 Hz，11025 Hz，12000 Hz，16000 Hz，22050 Hz，24000 Hz，32000 Hz，44100 Hz，或者 48000 Hz 采样，
*   样本可以在 8 位无符号或 16 位有符号(精度更高)上以**小端**或**大端**编码。

在下面的逐步教程中，我们将使用一个以小端字节序编码的 16 位原始 PCM 文件。

### 注

由此产生的项目以`DroidBlaster_Part12`的名称提供本书。

# 行动时间-创建和播放声音缓冲队列

让我们使用 OpenSL ES 播放存储在内存缓冲区中的爆炸声音:

1.  再次更新`jni/Resource.hpp`添加新方法`getLength()`，提供`asset`文件的字节大小:

    ```cpp
    ...
    class Resource {
    public:
        ...

        ResourceDescriptor descriptor();
        off_t getLength();
        ...
    };

    #endif
    ```

2.  在`jni/Resource.cpp` :

    ```cpp
    ...
    off_t Resource::getLength() {
        return AAsset_getLength(mAsset);
    }
    ...
    ```

    执行此方法
3.  Create `jni/Sound.hpp` to manage a sound buffer.

    定义加载 PCM 文件的方法`load()`和释放 PCM 文件的方法`unload()`。

    另外，定义合适的吸气剂。将原始声音数据及其大小保存在缓冲区中。声音来自一个`Resource`:

    ```cpp
    #ifndef _PACKT_SOUND_HPP_
    #define _PACKT_SOUND_HPP_

    class SoundManager;

    #include "Resource.hpp"
    #include "Types.hpp"

    class Sound {
    public:
        Sound(android_app* pApplication, Resource* pResource);

        const char* getPath();
        uint8_t* getBuffer() { return mBuffer; };
        off_t getLength() { return mLength; };

        status load();
        status unload();

    private:
        friend class SoundManager;

        Resource* mResource;
        uint8_t* mBuffer; off_t mLength;
    };
    #endif
    ```

4.  声音加载实现在`jni/Sound.cpp` 中完成相当简单；它会创建一个与 PCM 文件大小相同的缓冲区，并在其中加载所有原始文件内容:

    ```cpp
    #include "Log.hpp"
    #include "Sound.hpp"

    #include <SLES/OpenSLES.h>
    #include <SLES/OpenSLES_Android.h>

    Sound::Sound(android_app* pApplication, Resource* pResource) :
        mResource(pResource),
        mBuffer(NULL), mLength(0)
    {}

    const char* Sound::getPath() {
        return mResource->getPath();
    }

    status Sound::load() {
        Log::info("Loading sound %s", mResource->getPath());
        status result;

        // Opens sound file.
        if (mResource->open() != STATUS_OK) {
            goto ERROR;
        }

        // Reads sound file.
        mLength = mResource->getLength();
        mBuffer = new uint8_t[mLength];
        result = mResource->read(mBuffer, mLength);
        mResource->close();
        return STATUS_OK;

    ERROR:
        Log::error("Error while reading PCM sound.");
        return STATUS_KO;
    }

    status Sound::unload() {
        delete[] mBuffer;
        mBuffer = NULL; mLength = 0;

        return STATUS_OK;
    }
    ```

5.  Create `jni/SoundQueue.hpp` to encapsulate the creation of a player object and its queue. Create three methods to:
    *   当应用开始分配 OpenSL 资源时，初始化`queue`
    *   最终确定`queue`以释放 OpenSL 资源
    *   播放预定长度的声音缓冲区

    声音队列可以通过`SLPlayItf`和`SLBufferQueueItf`界面进行操作:

    ```cpp
    #ifndef _PACKT_SOUNDQUEUE_HPP_
    #define _PACKT_SOUNDQUEUE_HPP_

    #include "Sound.hpp"

    #include <SLES/OpenSLES.h>
    #include <SLES/OpenSLES_Android.h>

    class SoundQueue {
    public:
        SoundQueue();

        status initialize(SLEngineItf pEngine, SLObjectItf pOutputMixObj);
        void finalize();
        void playSound(Sound* pSound);

    private:
        SLObjectItf mPlayerObj; SLPlayItf mPlayer;
        SLBufferQueueItf mPlayerQueue;
    };
    #endif
    ```

6.  执行`jni/SoundQueue.cpp` :

    ```cpp
    #include "Log.hpp"
    #include "SoundQueue.hpp"

    SoundQueue::SoundQueue() :
        mPlayerObj(NULL), mPlayer(NULL),
        mPlayerQueue() {
    }
    ...
    ```

7.  写`initialize()`，从`SLDataSource`和`SLDataSink`开始描述输入输出通道。使用包含采样、编码和字符顺序信息的`SLDataFormat_PCM`数据格式(而不是`SLDataFormat_MIME`)。声音需要是单声道的(也就是说，如果可用，左右扬声器只能有一个声道)。该队列是用安卓专用扩展`SLDataLocator_AndroidSimpleBufferQueue()` :

    ```cpp
    ...
    status SoundQueue::initialize(SLEngineItf pEngine,
            SLObjectItf pOutputMixObj) {
        Log::info("Starting sound player.");
        SLresult result;

        // Set-up sound audio source.
        SLDataLocator_AndroidSimpleBufferQueue dataLocatorIn;
        dataLocatorIn.locatorType =
            SL_DATALOCATOR_ANDROIDSIMPLEBUFFERQUEUE;
        // At most one buffer in the queue.
        dataLocatorIn.numBuffers = 1;

        SLDataFormat_PCM dataFormat;
        dataFormat.formatType = SL_DATAFORMAT_PCM;
        dataFormat.numChannels = 1; // Mono sound.
        dataFormat.samplesPerSec = SL_SAMPLINGRATE_44_1;
        dataFormat.bitsPerSample = SL_PCMSAMPLEFORMAT_FIXED_16;
        dataFormat.containerSize = SL_PCMSAMPLEFORMAT_FIXED_16;
        dataFormat.channelMask = SL_SPEAKER_FRONT_CENTER;
        dataFormat.endianness = SL_BYTEORDER_LITTLEENDIAN;

        SLDataSource dataSource;
        dataSource.pLocator = &dataLocatorIn;
        dataSource.pFormat = &dataFormat;

        SLDataLocator_OutputMix dataLocatorOut;
        dataLocatorOut.locatorType = SL_DATALOCATOR_OUTPUTMIX;
        dataLocatorOut.outputMix = pOutputMixObj;

        SLDataSink dataSink;
        dataSink.pLocator = &dataLocatorOut;
        dataSink.pFormat = NULL;
    ...
    ```

    创建的
8.  然后，创建并实现声音播放器。我们要去需要它的`SL_IID_PLAY`和`SL_IID_BUFFERQUEUE`界面，由于上一步配置的数据定位器

    ```cpp
    ...
        const SLuint32 soundPlayerIIDCount = 2;
        const SLInterfaceID soundPlayerIIDs[] =
            { SL_IID_PLAY, SL_IID_BUFFERQUEUE };
        const SLboolean soundPlayerReqs[] =
            { SL_BOOLEAN_TRUE, SL_BOOLEAN_TRUE };

        result = (*pEngine)->CreateAudioPlayer(pEngine, &mPlayerObj,
            &dataSource, &dataSink, soundPlayerIIDCount,
            soundPlayerIIDs, soundPlayerReqs);
        if (result != SL_RESULT_SUCCESS) goto ERROR;
        result = (*mPlayerObj)->Realize(mPlayerObj, SL_BOOLEAN_FALSE);
        if (result != SL_RESULT_SUCCESS) goto ERROR;

        result = (*mPlayerObj)->GetInterface(mPlayerObj, SL_IID_PLAY,
            &mPlayer);
        if (result != SL_RESULT_SUCCESS) goto ERROR;
        result = (*mPlayerObj)->GetInterface(mPlayerObj,
            SL_IID_BUFFERQUEUE, &mPlayerQueue);
        if (result != SL_RESULT_SUCCESS) goto ERROR;
    ...
    ```

    可用
9.  最后，通过将队列设置为播放状态来启动队列。这实际上并不意味着播放了声音。队列是空的，所以这是不可能的。但是，如果声音入队，则会自动播放:

    ```cpp
    ...
        result = (*mPlayer)->SetPlayState(mPlayer,
            SL_PLAYSTATE_PLAYING);
        if (result != SL_RESULT_SUCCESS) goto ERROR;
        return STATUS_OK;

    ERROR:
        Log::error("Error while starting SoundQueue");
        return STATUS_KO;
    }
    ...
    ```

10.  OpenSL ES 对象需要在我们不再需要它们的时候释放:

    ```cpp
    ...
    void SoundQueue::finalize() {
        Log::info("Stopping SoundQueue.");

        if (mPlayerObj != NULL) {
            (*mPlayerObj)->Destroy(mPlayerObj);
            mPlayerObj = NULL; mPlayer = NULL; mPlayerQueue = NULL;
        }
    }
    ...
    ```

11.  最后写`playSound()`，首先停止任何正在播放的声音，然后将新的声音缓冲区入队播放。这是立即播放声音的最简单策略:

    ```cpp
    ...
    void SoundQueue::playSound(Sound* pSound) {
        SLresult result;
        SLuint32 playerState;
        (*mPlayerObj)->GetState(mPlayerObj, &playerState);
        if (playerState == SL_OBJECT_STATE_REALIZED) {
            int16_t* buffer = (int16_t*) pSound->getBuffer();
            off_t length = pSound->getLength();

            // Removes any sound from the queue.
            result = (*mPlayerQueue)->Clear(mPlayerQueue);
            if (result != SL_RESULT_SUCCESS) goto ERROR;
            // Plays the new sound.
            result = (*mPlayerQueue)->Enqueue(mPlayerQueue, buffer,
                                              length);
            if (result != SL_RESULT_SUCCESS) goto ERROR;
        }
        return;

    ERROR:
        Log::error("Error trying to play sound");
    }
    ```

12.  Open `jni/SoundManager.hpp` and include the newly created headers.

    创建两种新方法:

    *   `registerSound()`加载和管理新的声音缓冲区
    *   `playSound()`向声音播放队列发送声音缓冲区

    定义一个`SoundQueue`数组，这样最多可以同时播放四种声音。

    声音缓冲区存储在固定大小的 C++ 数组中:

    ```cpp
    ...
    #include "Sound.hpp"
    #include "SoundQueue.hpp"
    #include "Types.hpp"
    ...

    class SoundManager {
    public:
        SoundManager(android_app* pApplication);
        ~SoundManager();

        ...

        Sound* registerSound(Resource& pResource);
     void playSound(Sound* pSound);

    private:
        ...
        static const int32_t QUEUE_COUNT = 4;
     SoundQueue mSoundQueues[QUEUE_COUNT]; int32_t mCurrentQueue;
     Sound* mSounds[32]; int32_t mSoundCount;
    };
    #endif
    ```

13.  更新`jni/SoundManager.cpp` 中的构造函数，新建一个析构函数释放资源:

    ```cpp
    ...
    SoundManager::SoundManager(android_app* pApplication) :
        mApplication(pApplication),
        mEngineObj(NULL), mEngine(NULL),
        mOutputMixObj(NULL),
        mBGMPlayerObj(NULL), mBGMPlayer(NULL), mBGMPlayerSeek(NULL),
        mSoundQueues(), mCurrentQueue(0),
     mSounds(), mSoundCount(0) {
        Log::info("Creating SoundManager.");
    }

    SoundManager::~SoundManager() {
     Log::info("Destroying SoundManager.");
     for (int32_t i = 0; i < mSoundCount; ++ i) {
     delete mSounds[i];
     }
     mSoundCount = 0;
    }
    ...
    ```

14.  更新`start()`以初始化`SoundQueue`实例。然后，加载`registerSound()`注册的声音资源:

    ```cpp
    ...
    status SoundManager::start() {
        ...
        result = (*mEngine)->CreateOutputMix(mEngine, &mOutputMixObj,
            outputMixIIDCount, outputMixIIDs, outputMixReqs);
        result = (*mOutputMixObj)->Realize(mOutputMixObj,
            SL_BOOLEAN_FALSE);

        Log::info("Starting sound player.");
     for (int32_t i= 0; i < QUEUE_COUNT; ++ i) {
     if (mSoundQueues[i].initialize(mEngine, mOutputMixObj)
     != STATUS_OK) goto ERROR;
        }

        for (int32_t i = 0; i < mSoundCount; ++ i) {
     if (mSounds[i]->load() != STATUS_OK) goto ERROR;
        }
        return STATUS_OK;

    ERROR:
        ...
    }
    ...
    ```

15.  当应用停止释放 OpenSL ES 资源时，完成`SoundQueue`实例。另外，释放声音缓冲器:

    ```cpp
    ...
    void SoundManager::stop() {
        Log::info("Stopping SoundManager.");
        stopBGM();

        for (int32_t i= 0; i < QUEUE_COUNT; ++ i) {
     mSoundQueues[i].finalize();
        }

        // Destroys audio output and engine.
        ...

        for (int32_t i = 0; i < mSoundCount; ++ i) {
     mSounds[i]->unload();
        }
    }
    ...
    ```

16.  保存并缓存`registerSound()` :

    ```cpp
    ...
    Sound* SoundManager::registerSound(Resource& pResource) {
        for (int32_t i = 0; i < mSoundCount; ++ i) {
            if (strcmp(pResource.getPath(), mSounds[i]->getPath()) == 0) {
                return mSounds[i];
            }
        }

        Sound* sound = new Sound(mApplication, &pResource);
        mSounds[mSoundCount++ ] = sound;
        return sound;
    }
    ...
    ```

    中的声音
17.  最后写`playSound()`，发送缓冲区播放给一个`SoundQueue`。使用简单的循环策略同时播放几个声音。将每个新的声音发送到队列中的下一个播放位置(更有可能是)。显然，这种播放策略对于各种长度的声音来说是次优的:

    ```cpp
    ...
    void SoundManager::playSound(Sound* pSound) {
        int32_t currentQueue = ++ mCurrentQueue;
        SoundQueue& soundQueue = mSoundQueues[currentQueue % QUEUE_COUNT];
        soundQueue.playSound(pSound);
    }
    ```

18.  We will play a sound when the DroidBlaster ship collides with an asteroid. Since the collision is not yet managed (see [Chapter 10](10.html "Chapter 10. Intensive Computing with RenderScript"), *Intensive Computing with RenderScript* for collision handling with **Box2D**), we will simply play a sound when the ship is initialized.

    为此，在`jni/Ship.hpp`中，检索构造函数中对`SoundManager`的引用和要在`registerShip()`中播放的碰撞声音缓冲区:

    ```cpp
    ...
    #include "GraphicsManager.hpp"
    #include "Sprite.hpp"
    #include "SoundManager.hpp"
    #include "Sound.hpp"

    class Ship {
    public:
        Ship(android_app* pApplication,
             GraphicsManager& pGraphicsManager,
             SoundManager& pSoundManager);

        void registerShip(Sprite* pGraphics, Sound* pCollisionSound);

        void initialize();

    private:
        GraphicsManager& mGraphicsManager;
        SoundManager& mSoundManager;

        Sprite* mGraphics;
        Sound* mCollisionSound;
    };
    #endif
    ```

19.  然后，在`jni/Ship.cpp`中，在存储了所有必要的参考后，当飞船初始化时播放声音:

    ```cpp
    ...
    Ship::Ship(android_app* pApplication,
            GraphicsManager& pGraphicsManager,
            SoundManager& pSoundManager) :
      mGraphicsManager(pGraphicsManager),
      mGraphics(NULL),
      mSoundManager(pSoundManager),
     mCollisionSound(NULL) {
    }

    void Ship::registerShip(Sprite* pGraphics, Sound* pCollisionSound) {
        mGraphics = pGraphics;
        mCollisionSound = pCollisionSound;
    }

    void Ship::initialize() {
        mGraphics->location.x = INITAL_X
                * mGraphicsManager.getRenderWidth();
        mGraphics->location.y = INITAL_Y
                * mGraphicsManager.getRenderHeight();
        mSoundManager.playSound(mCollisionSound);
    }
    ```

20.  在`jni/DroidBlaster.hpp`中，定义对文件的引用，该文件包含碰撞声:

    ```cpp
    ...
    class DroidBlaster : public ActivityHandler {
        ...

    private:
        ...
        Resource mAsteroidTexture;
        Resource mShipTexture;
        Resource mStarTexture;
        Resource mBGM;
        Resource mCollisionSound;

        ...
    };
    #endif
    ```

21.  最后，在 `jni/DroidBlaster.cpp`中，注册新的音并传递给`Ship`类:

    ```cpp
    #include "DroidBlaster.hpp"
    #include "Sound.hpp"
    #include "Log.hpp"
    ...
    DroidBlaster::DroidBlaster(android_app* pApplication):
        ...
        mAsteroidTexture(pApplication, "droidblaster/asteroid.png"),
        mShipTexture(pApplication, "droidblaster/ship.png"),
        mStarTexture(pApplication, "droidblaster/star.png"),
        mBGM(pApplication, "droidblaster/bgm.mp3"),
        mCollisionSound(pApplication, "droidblaster/collision.pcm"),

        mAsteroids(pApplication, mTimeManager, mGraphicsManager,
                mPhysicsManager),
        mShip(pApplication, mGraphicsManager, mSoundManager),
        mStarField(pApplication, mTimeManager, mGraphicsManager,
                STAR_COUNT, mStarTexture),
        mSpriteBatch(mTimeManager, mGraphicsManager) {
        Log::info("Creating DroidBlaster");

        Sprite* shipGraphics = mSpriteBatch.registerSprite(mShipTexture,
                SHIP_SIZE, SHIP_SIZE);
        shipGraphics->setAnimation(SHIP_FRAME_1, SHIP_FRAME_COUNT,
                SHIP_ANIM_SPEED, true);
        Sound* collisionSound =
     mSoundManager.registerSound(mCollisionSound);
     mShip.registerShip(shipGraphics, collisionSound);
        ...
    }
    ...
    ```

## *刚刚发生了什么？*

我们发现了如何将声音预加载到缓冲区中，并根据需要播放它们。声音播放技术与前面看到的 BGM 的区别在于使用了缓冲队列。缓冲队列正是它的名字所揭示的:一个声音缓冲区的集合，一个接一个地播放。当播放完所有先前的缓冲区时，缓冲区会排队等待播放。

缓冲液可以回收。这种技术与流文件相结合是必不可少的:两个或更多的缓冲区被填满并发送到队列。当第一个缓冲区结束播放时，第二个缓冲区开始播放，同时第一个缓冲区充满新数据。在队列变空之前，第一个缓冲区会尽快排队。这个过程一直重复，直到播放结束。此外，缓冲区是原始数据，因此可以动态处理或过滤。

在本教程中，因为`DroidBlaster`不需要一次播放多个声音，也不需要任何形式的流，所以缓冲队列大小简单地设置为一个缓冲区(步骤 7，`dataLocatorIn.numBuffers = 1;`)。此外，我们希望新的声音取代旧的声音，这解释了为什么队列会被系统地清理掉。您的 OpenSL ES 架构当然应该适应您的需求。如果有必要同时播放几个声音，应该创建几个音频播放器(从而创建缓冲队列)。

声音缓冲区以 PCM 格式存储，这种格式不能自我描述其内部格式。需要在应用代码中选择采样、编码和其他格式信息。虽然这对于他们中的大多数人来说都很好，但是如果不够灵活，一个解决方案是加载一个 Wave 文件，其中包含所有必要的头信息。

### 类型

过滤和排序声音的一个很好的开源工具是 **Audacity** 。它允许改变采样率和修改通道(单声道/立体声)。Audacity 能够将声音作为原始 PCM 数据导出和导入。

## 使用回调检测声音队列事件

可以通过回调来检测声音何时播放完毕。回调可以通过在队列上调用`RegisterCallback()`方法来设置(但是其他类型的对象也可以注册回调)。例如，回调可以接收这个，也就是一个`SoundManager`自引用，如果需要的话，允许处理任何上下文信息。虽然这是兼性的，但设置了一个事件掩码，以确保只有在触发`SL_PLAYEVENT_HEADATEND`(玩家已经玩完缓冲区)事件时才会调用回调。在`OpenSLES.h`中还有一些其他的比赛项目:

```cpp
...
void callback_sound(SLBufferQueueItf pBufferQueue, void *pContext) {
 // Context can be casted back to the original type.
 SoundService& lService = *(SoundService*) pContext;
    ...
    Log::info("Ended playing sound.");
}
...
status SoundService::start() {
    ...
    result = (*mEngine)->CreateOutputMix(mEngine, &mOutputMixObj,
        outputMixIIDCount, outputMixIIDs, outputMixReqs);
    result = (*mOutputMixObj)->Realize(mOutputMixObj,
        SL_BOOLEAN_FALSE);

    // Registers a callback called when sound is finished.
 result = (*mPlayerQueue)->RegisterCallback(mPlayerQueue,
 callback_sound, this);
 if (result != SL_RESULT_SUCCESS) goto ERROR;
 result = (*mPlayer)->SetCallbackEventsMask(mPlayer,
 SL_PLAYEVENT_HEADATEND);
 if (result != SL_RESULT_SUCCESS) goto ERROR;

    Log::info("Starting sound player.");
    ...
}
...
```

现在，当缓冲区结束播放时，会记录一条消息。可以执行新缓冲区的排队(例如处理流)等操作。

## 安卓低延迟

回调就像系统中断或应用事件一样，它们的处理必须短而快。如果高级处理是必要的，它不应该在回调内部执行，而应该在另一个线程上执行——本机线程是完美的候选线程。

事实上，回调是在系统线程上发出的，不同于请求 OpenSL ES 服务的线程(在我们的例子中是`NativeActivity`本地线程)。当然，对于线程，当从回调访问您自己的变量时，会出现线程安全的问题。虽然用互斥锁保护代码很诱人，但它们不是处理实时音频的最佳方式。它们对调度的影响(**优先级反转【例如 T2】问题)可能会导致播放过程中出现故障。**

因此，更喜欢使用线程安全技术，比如无锁队列来与回调通信。无锁技术可以使用 GCC 内置的原子函数来实现，比如`__sync_fetch_and_add()`(不需要任何包含文件)。有关安卓 NDK 系统原子操作的更多信息，请查看`${ANDROID_NDK}/docs/ANDROID-ATOMICS.html`。

虽然适当的无锁代码对于在安卓上实现低延迟至关重要，但另一个需要考虑的要点是，并不是所有的安卓平台和设备都适合它！事实上，从操作系统版本 4.1/4.2 开始，安卓对低延迟的支持来得相当晚。如果您需要低延迟，您可以用下面这段 Java 代码来检查它的支持:

```cpp
import android.content.pm.PackageManager;
...
PackageManager pm = getContext().getPackageManager();
boolean claimsFeature = pm.hasSystemFeature(PackageManager.FEATURE_AUDIO_LOW_LATENCY);
```

但是，要小心！由于驱动程序问题，许多设备，即使是最新的系统版本，也无法实现低延迟。

一旦您知道目标平台支持低延迟，请注意使用适当的采样率和缓冲区大小。事实上，安卓音频系统提供了一个“快速路径”，当使用最佳配置时，它不会应用任何重采样。为此，从 API 级别 17 或更高，从 Java 端使用`android.media.AudioManager.getProperty()`:

```cpp
import android.media.AudioManager;
...
AudioManager am = (AudioManager) getSystemService(Context.AUDIO_SERVICE);
String sampleRateStr =
        am.getProperty(AudioManager.PROPERTY_OUTPUT_SAMPLE_RATE);
int sampleRate = !TextUtils.isEmpty(sampleRateStr) ?
                                Integer.parseInt(sampleRateStr) : -1;
String framesPerBufferStr =
        am.getProperty(AudioManager.PROPERTY_OUTPUT_FRAMES_PER_BUFFER);
int framesPerBuffer = !TextUtils.isEmpty(framesPerBufferStr) ?
                           Integer.parseInt(framesPerBufferStr) : -1;
```

更多关于这个主题的信息，请看*高性能* *音频*在[https://developers.google.com/events/io/sessions/325993827](https://developers.google.com/events/io/sessions/325993827)的谈话。

# 记录声音

安卓设备都是关于互动的。交互不仅可以来自触摸和传感器，还可以来自音频输入。大多数安卓设备都提供麦克风来记录声音，并允许安卓桌面搜索等应用提供声音功能来记录查询。

如果声音输入可用，OpenSL ES 允许本机访问录音机。它与缓冲队列协作，从输入设备获取数据，并从中填充输出声音缓冲区。除了数据源和数据接收器被置换之外，设置与`AudioPlayer`非常相似。

## 玩一个围棋英雄——录制和播放声音

要了解录制的工作原理，请在应用启动时录制声音，并在完成录制后播放声音。将`SoundManager`变成记录仪可以分四步完成:

1.  使用状态`startSoundRecorder()`初始化录音机。在`startSoundPlayer()`之后立即调用它。
2.  使用 void `recordSound()`，用设备微型开始录制声音缓冲。在背景音乐播放开始后，应用在`onActivate()`中被激活时，调用此方法。
3.  一个新的回调静态`void callback_recorder(SLAndroidSimpleBufferQueueItf, void*)`被通知记录队列事件。您必须注册这个回调，以便在记录器事件发生时触发它。这里我们感兴趣的是缓冲区满事件，也就是录音结束的时候。
4.  `void playRecordedSound()` to play a sound once recorded. Play it at instances such as when the sound has finished being recorded in `callback_recorder()`. This is not technically correct because of potential race conditions but is fine for an illustration.

    ### 注

    由此产生的项目以`DroidBlaster_PartRecorder`的名称提供本书。

在继续之前，录制需要特定的安卓许可，当然，还需要合适的安卓设备(你不会希望应用在背后录制你的秘密对话！).必须在安卓清单中请求该授权:

```cpp
<?xml version="1.0" encoding="utf-8"?>
<manifest xmlns:android="http://schemas.android.com/apk/res/android"
    package="com.packtpub.droidblaster2d" android:versionCode="1"
    android:versionName="1.0">
    ...
    <uses-permission android:name="android.permission.RECORD_AUDIO"/>
</manifest>
```

## 创建和释放记录器

像往常一样，声音是用 OpenSL ES 引擎创建的记录器对象记录的。记录仪提供了两个有趣的界面:

*   `SLRecordItf`:此界面用于开始和停止录制。标识符为`SL_IID_RECORD`。
*   `SLAndroidSImpleBufferQueueItf`:这为录音机管理一个声音队列。这是 NDK 提供的安卓扩展，因为当前的 OpenSL ES 1.0.1 规范不支持记录到队列。标识符为`SL_IID_ANDROIDSIMPLEBUFFERQUEUE` :

    ```cpp
    const SLuint32 soundRecorderIIDCount = 2;
    const SLInterfaceID soundRecorderIIDs[] =
            { SL_IID_RECORD, SL_IID_ANDROIDSIMPLEBUFFERQUEUE };
    const SLboolean soundRecorderReqs[] =
            { SL_BOOLEAN_TRUE, SL_BOOLEAN_TRUE };
    SLObjectItf mRecorderObj;
    (*mEngine)->CreateAudioRecorder(mEngine, &mRecorderObj,
            &dataSource, &dataSink,
            soundRecorderIIDCount, soundRecorderIIDs, soundRecorderReqs);
    ```

要创建录音机，您需要声明音频源和接收器，类似于下面的例子。数据源不是声音，而是默认的录音设备(如麦克风)。另一方面，数据接收器(即输出通道)不是扬声器，而是 PCM 格式的声音缓冲区(具有请求的采样、编码和字符顺序)。安卓扩展`SLDataLocator_AndroidSimpleBufferQueue`必须用于记录器，因为标准 OpenSL 缓冲队列不会:

```cpp
SLDataLocator_AndroidSimpleBufferQueue dataLocatorOut;
dataLocatorOut.locatorType =
    SL_DATALOCATOR_ANDROIDSIMPLEBUFFERQUEUE;
dataLocatorOut.numBuffers = 1;

SLDataFormat_PCM dataFormat;
dataFormat.formatType = SL_DATAFORMAT_PCM;
dataFormat.numChannels = 1;
dataFormat.samplesPerSec = SL_SAMPLINGRATE_44_1;
dataFormat.bitsPerSample = SL_PCMSAMPLEFORMAT_FIXED_16;
dataFormat.containerSize = SL_PCMSAMPLEFORMAT_FIXED_16;
dataFormat.channelMask = SL_SPEAKER_FRONT_CENTER;
dataFormat.endianness = SL_BYTEORDER_LITTLEENDIAN;

SLDataSink dataSink;
dataSink.pLocator = &dataLocatorOut;
dataSink.pFormat = &dataFormat;

SLDataLocator_IODevice dataLocatorIn;
dataLocatorIn.locatorType = SL_DATALOCATOR_IODEVICE;
dataLocatorIn.deviceType = SL_IODEVICE_AUDIOINPUT;
dataLocatorIn.deviceID = SL_DEFAULTDEVICEID_AUDIOINPUT;
dataLocatorIn.device = NULL;

SLDataSource dataSource;
dataSource.pLocator = &dataLocatorIn;
dataSource.pFormat = NULL;
```

当一个应用结束时，不要忘记释放记录器对象作为所有其他 OpenSL 对象。

## 记录声音

要录制声音，您需要根据录制的持续时间创建一个大小合适的声音缓冲区。您可以调整`Sound`类以允许创建给定大小的空缓冲区。大小取决于采样率。例如，对于采样率为`44100`赫兹、`16`位质量的`2`秒记录，声音缓冲区大小如下所示:

```cpp
recordSize   = 2 * 44100 * sizeof(int16_t);
recordBuffer = new int16_t[mRecordSize];
```

在`recordSound()`中，首先停止记录仪，感谢`SLRecordItf`，确保它不是已经在记录。然后，清除队列以确保记录缓冲区被立即使用。最后，您可以将新的缓冲区排队并开始记录:

```cpp
(*mRecorder)->SetRecordState(mRecorder, SL_RECORDSTATE_STOPPED);
(*mRecorderQueue)->Clear(mRecorderQueue);
(*mRecorderQueue)->Enqueue(mRecorderQueue, recordBuffer,
    recordSize * sizeof(int16_t));
(*mRecorder)->SetRecordState(mRecorder,SL_RECORDSTATE_RECORDING);
```

### 类型

将新的声音缓冲区入队是完全可能的，这样任何当前的记录都将被处理到其结束。这允许创建连续的记录链，或者换句话说，流式传输记录。入队的声音只有在前一个声音被填充后才会被处理。

## 记录回拨

您最终需要知道您的声音缓冲区何时完成录制。为此，注册当记录器事件发生时触发的回调(例如，缓冲区已被填满)。应该设置一个事件掩码，以确保回调仅在缓冲区已被填充时调用(`SL_RECORDEVENT_BUFFER_FULL`)。其他几个在`OpenSLES.h`中有，但不是全部都支持(`SL_RECORDEVENT_HEADATLIMIT`等等):

```cpp
(*mRecorderQueue)->RegisterCallback(mRecorderQueue,
                                    callback_recorder, this);
(*mRecorder)->SetCallbackEventMask(mRecorder,
                                   SL_RECORDEVENT_BUFFER_FULL);
```

最后当`callback_recorder()`被触发时，停止录制，用`playRecordedSound()`播放录制好的缓冲区。录制的缓冲区需要在音频播放器的队列中排队播放，就像我们在上一节中所做的那样。为了简单起见，您可以使用特定的`SoundQueue`来播放声音。

# 总结

总之，我们在这一章看到了如何在安卓上初始化 OpenSL ES。引擎对象是管理所有 OpenSL 对象的主要入口点。OpenSL 中的对象遵循特定的创建、实现和销毁生命周期。然后，我们看到了如何使用声音缓冲队列播放编码文件中的背景音乐和内存中的声音。最后，我们发现了如何以线程安全和无阻塞的方式录制和播放声音。

比起 Java APIs，你更喜欢 OpenSL ES 吗？如果你只需要一个好的高级应用编程接口，那么 Java 应用编程接口可能更适合你的需求。如果您需要更精细的回放或录制控制，低级 Java APIs 和 OpenSL ES 之间没有显著的区别。在这种情况下，选择应该是建筑。如果你的代码主要是 Java，你可能应该用 Java。

如果您需要重用现有的声音相关库、优化性能或执行密集的计算，例如动态声音过滤，OpenSL ES 可能是正确的选择。OpenSL ES 也是通往低延迟的道路，尽管 Android 还没有完全实现(碎片化、设备特定的问题等等)。至少，这个冗长的 API 可能会提供最好的性能。没有垃圾收集器开销，并且在本机代码中支持积极的优化。

无论你做出什么选择，都要知道安卓 NDK 还有很多可以提供的。在处理完[第 6 章](06.html "Chapter 6. Rendering Graphics with OpenGL ES")、*用 OpenGL ES 渲染图形*和[第 7 章](# "Chapter 7. Playing Sound with OpenSL ES")、*用 OpenSL ES* 播放声音后，下一章将关注本机处理输入:键盘、触摸和传感器。